{"pages":[{"title":"about","text":"从事Android开发5年有余.","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"friends","text":"","link":"/friends/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Android事件分发机制(一)","text":"前言Android事件分发机制是Android开发中最基础的知识，在平时的开发中没有少用，但是确很少总结。温故而知新，为此我决定重新分析一下，也是对自己的经验做下总结。 TestDispatchAct: ==================dispatchTouchEvent================== TestDispatchGroup: ==================dispatchTouchEvent================== TestDispatchGroup: ==================onInterceptTouchEvent================== TestDispatchView: ==================dispatchTouchEvent================== TestDispatchView: ==================onTouchEvent================== TestDispatchView: MotionEvent { action=ACTION_DOWN } TestDispatchGroup: ==================onTouchEvent================== TestDispatchGroup: MotionEvent { action=ACTION_DOWN } TestDispatchAct: ==================onTouchEvent================== TestDispatchAct: MotionEvent { action=ACTION_DOWN } TestDispatchAct: ==================dispatchTouchEvent================== TestDispatchAct: ==================onTouchEvent================== TestDispatchAct: MotionEvent { action=ACTION_MOVE } TestDispatchAct: ==================dispatchTouchEvent================== TestDispatchAct: ==================onTouchEvent================== TestDispatchAct: MotionEvent { action=ACTION_UP } 当不做任何处理时，发现事件从最外层向最内层传递，最终将事件交回最外层处理，流程图如下: 可以看到事件从最外层Activity传递到最内层View的onTouchEvent，这时View是把事件交回父类处理的，最终又回到Activity，并在Activity的onTouchEvent消费了ACTION_DOWN，接下来的ACTION_MOVE与ACTION_UP事件则直接在Activity被消费了，并不会再往下分发。 接下来看看如果在ViewGroup中如果消费了事件，流程又有什么改变。 TestDispatchAct: ==================dispatchTouchEvent================== TestDispatchGroup: ==================dispatchTouchEvent================== TestDispatchGroup: ==================onInterceptTouchEvent================== TestDispatchView: ==================dispatchTouchEvent================== TestDispatchView: ==================onTouchEvent================== TestDispatchView: MotionEvent { action=ACTION_DOWN } TestDispatchGroup: ==================onTouchEvent================== TestDispatchGroup: MotionEvent { action=ACTION_DOWN } TestDispatchAct: ==================dispatchTouchEvent================== TestDispatchGroup: ==================dispatchTouchEvent================== TestDispatchGroup: ==================onTouchEvent================== TestDispatchGroup: MotionEvent { action=ACTION_MOVE } TestDispatchAct: ==================dispatchTouchEvent================== TestDispatchGroup: ==================dispatchTouchEvent================== TestDispatchGroup: ==================onTouchEvent================== TestDispatchGroup: MotionEvent { action=ACTION_MOVE } TestDispatchAct: ==================dispatchTouchEvent================== TestDispatchGroup: ==================dispatchTouchEvent================== TestDispatchGroup: ==================onTouchEvent================== TestDispatchGroup: MotionEvent { action=ACTION_UP } 可以看到一旦事件被消费了，就不会再往上传递到Activity了，并且在接下来的事件中，事件分发也只会传递到ViewGroup并被它消费掉，流程图如下： 接下来在ViewGroup的onInterceptTouchEvent中将事件拦截掉，看流程又有何变化。 TestDispatchAct: ==================dispatchTouchEvent================== TestDispatchGroup: ==================dispatchTouchEvent================== TestDispatchGroup: ==================onInterceptTouchEvent================== TestDispatchGroup: ==================onTouchEvent================== TestDispatchGroup: MotionEvent { action=ACTION_DOWN } TestDispatchAct: ==================onTouchEvent================== TestDispatchAct: MotionEvent { action=ACTION_DOWN } TestDispatchAct: ==================dispatchTouchEvent================== TestDispatchAct: ==================onTouchEvent================== TestDispatchAct: MotionEvent { action=ACTION_MOVE } TestDispatchAct: ==================dispatchTouchEvent================== TestDispatchAct: ==================onTouchEvent================== TestDispatchAct: MotionEvent { action=ACTION_MOVE } TestDispatchAct: ==================dispatchTouchEvent================== TestDispatchAct: ==================onTouchEvent================== TestDispatchAct: MotionEvent { action=ACTION_UP } 通过日志，可以看到事件被ViewGroup拦截后，不再往下分发，直接执行的是ViewGroup的onTouchEvent，由于此时ViewGroup没有消费事件，所以所有的事件都交还给了Activity去处理，流程如下图所示： 疑问 为什么ACTION_DOWN事件逐层分发，但是ViewGroup消费之后就不会继续向下分发了呢？ 要弄清楚这个问题就必须更进一步阅读ViewGroup和View的源码，下一小节中，我将从源码的角度去分析事件分发的原理。 参考重学安卓：学习 View 事件分发，就像外地人上了黑车！by KunMinX","link":"/2019/09/21/Android%E4%BA%8B%E4%BB%B6%E5%88%86%E5%8F%91%E6%9C%BA%E5%88%B6part1/"},{"title":"Android代码混淆","text":"前言最近在用Kotlin撸App，准备发版了，做下代码混淆，想用原来的混淆逻辑，但是发现各种报错，头大的很，觉得是自己关于混淆的知识积累不够多，是应该系统的学习一下了！顺便在此记录下遇到的坑。那下面我们开始吧。 代码混淆开启代码混淆只要在app.gradle文件下配置proguardFiles buildTypes { release { minifyEnabled true //是否开启混淆 zipAlignEnabled true //对齐zip debuggable false // 是否debug versionNameSuffix \"_release\" // 版本命名后缀 proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro' // 混淆文件 signingConfig signingConfigs.release } ... } proguard-android.txt 是android自带的混淆规则，我们只需要在proguard-rules.pro这个文件中配置我么的混淆规则就可以了。 Proguard混淆流程 压缩（shrink）：检测并移除代码中无用的类、字段、方法和特性 优化（optimize）：对字节码进行优化，移除无用指令 混淆（obfuscate）：使用a，b，c，d这样简短而无意义的名称，对类、字段和方法进行重命名 预检（preveirfy）：在java平台上对处理后的代码进行预检，确保加载的class文件时可执行的 混淆规则 Proguard关键字 描述 keep 保留类和类中的成员，防止被混淆或移除 keepnames 保留类和类中的成员，防止被混淆，成员没有被引用会被移除 keepclassmembers 只保留类中的成员，防止被混淆或移除 keepclassmembernames 只保留类中的成员，防止被混淆，成员没有引用会被移除 keepclasseswithmembers 保留类和类中的成员，防止被混淆或移除，保留指明的成员，前提是指名的类中的成员必须存在，如果不存在则还是会混淆。 keepclasseswithmembernames 保留类和类中的成员，防止被混淆，保留指明的成员，成员没有引用会被移除，前提是指名的类中的成员必须存在，如果不存在则还是会混淆。 通配符 描述 field 匹配类中的所有字段 method 匹配类中的所有方法 init 匹配类中的所有构造函数 * 匹配任意长度字符，但不含包名分隔符（.）。 ** 匹配任意长度字符，并且包含包名分隔符（.）。 *** 匹配任意参数类型 … 匹配任意长度任意类型参数 举例：我们完整的包名是com.xxx.ui.MainAct，使用com.*或者com.xxx.\\*都是无法匹配的，正确的写法是com.xxx.\\*.\\*，或者com.xxx.ui.* 避免混淆的因素 native method：因为native是根据方法名去调用的，若混淆后会导致找不到此方法名。 反射相关的方法和类：反射原理就是通过方法名和类名去实例化相应的对象，调用相关的方法。 setXX和getXX方法：这里指的是通过配置文件直接生成相应的set和get方法的相关库，所以javaBean类很多情况下不能做混淆。 第三方jar包：这个需要具体情况具体分析，很多库都会提供默认的混淆配置，大多数情况可以不用做混淆。 处理混淆失败问题通常混淆失败导致gradle构建项目失败，原因在输出的错误日志上并不明显，我们可以在Build Output中找到构建出错的task，例如我构建失败的任务是transformClassesAndResourcesWithProguardForBaiduRelease，因此我可以执行 gradlew transformClassesAndResourcesWithProguardForBaiduRelease -- stacktrace 这样我们就能在shell中看清楚到底是什么地方出错啦。 参考ProGuard manualAndroid混淆Android 代码混淆零基础入门ProGuard 最全混淆规则说明Android 混淆：proguard实践","link":"/2018/05/29/Android%E4%BB%A3%E7%A0%81%E6%B7%B7%E6%B7%86/"},{"title":"Android事件分发机制(二)","text":"前言接上节，在这一小节中，我将着重从View和ViewGroup的源码中去探索事件分发的流程是否如上小节分析的那样，带着上一节所留下的疑问开始愉快的阅读源码吧。 源码分析先放上小节中总结的流程图： 在Activity中最终也是走的ViewGroup.dispatchTouchEvent，所以直接看ViewGroup就可以了： 首先我们要明确一次完整的事件分发包括ACTION_DOWN，若干ACTION_MOVE，ACTION_UP事件 final int action = ev.getAction(); final int actionMasked = action &amp; MotionEvent.ACTION_MASK; // Handle an initial down. if (actionMasked == MotionEvent.ACTION_DOWN) { // Throw away all previous state when starting a new touch gesture. // The framework may have dropped the up or cancel event for the previous gesture // due to an app switch, ANR, or some other state change. cancelAndClearTouchTargets(ev); resetTouchState(); } 此处做重置工作，如果当前的MotionEvent是ACTION_DOWN，则cancel所有未执行完的事件，并清除所有的TouchTarget，这个TouchTarget是什么?它记录了所有被点击的View和MotionEvent的id，如果有设置FLAG_DISALLOW_INTERCEPT也会被一并清除掉。 // Check for interception. final boolean intercepted; if (actionMasked == MotionEvent.ACTION_DOWN || mFirstTouchTarget != null) { final boolean disallowIntercept = (mGroupFlags &amp; FLAG_DISALLOW_INTERCEPT) != 0; if (!disallowIntercept) { intercepted = onInterceptTouchEvent(ev); ev.setAction(action); // restore action in case it was changed } else { intercepted = false; } } else { // There are no touch targets and this action is not an initial down // so this view group continues to intercept touches. intercepted = true; } // If intercepted, start normal event dispatch. Also if there is already // a view that is handling the gesture, do normal event dispatch. if (intercepted || mFirstTouchTarget != null) { ev.setTargetAccessibilityFocus(false); } 此处判断事件是否被拦截，在这里我们看到了熟悉的onInterceptTouchEvent，当前事件为ACTION_DOWN时，首先会判断有没有设置FLAG_DISALLOW_INTERCEPT标识，这个标识是通过requestDisallowInterceptTouchEvent设置的，一般是子View控制父类不去拦截事件，前面分析到了这个flag会在执行ACTION_DOWN事件时被重置，如果不允许被拦截，那么事件当然交予子View去处理啦，反之，则会执行onInterceptTouchEvent方法。如果是其他的事件，则需要考虑mFirstTouchTarget是否为null，在下面的代码中可以看到如果事件交予子控件处理，那么mFirstTouchTarget将被赋值，因此如果事件没有交予子View处理，mFirstTouchTarget就是null值，那么接下来的所有事件都不会交予子View处理了，而且也不会执行onInterceptTouchEvent。 final View[] children = mChildren; for (int i = childrenCount - 1; i >= 0; i--) { final int childIndex = getAndVerifyPreorderedIndex(childrenCount, i, customOrder); final View child = getAndVerifyPreorderedView(preorderedList, children, childIndex); if (childWithAccessibilityFocus != null) { if (childWithAccessibilityFocus != child) { continue; } childWithAccessibilityFocus = null; i = childrenCount - 1; } // 判断子View是否能收到点击事件和点击事件是否在View内发生 if (!canViewReceivePointerEvents(child) || !isTransformedTouchPointInView(x, y, child, null)) { ev.setTargetAccessibilityFocus(false); // 如果子View收不到事件，进行下一从循环，一直到找到目标子View continue; } newTouchTarget = getTouchTarget(child); if (newTouchTarget != null) { // Child is already receiving touch within its bounds. // Give it the new pointer in addition to the ones it is handling. newTouchTarget.pointerIdBits |= idBitsToAssign; break; } resetCancelNextUpFlag(child); if (dispatchTransformedTouchEvent(ev, false, child, idBitsToAssign)) { // Child wants to receive touch within its bounds. mLastTouchDownTime = ev.getDownTime(); if (preorderedList != null) { // childIndex points into presorted list, find original index for (int j = 0; j &lt; childrenCount; j++) { if (children[childIndex] == mChildren[j]) { mLastTouchDownIndex = j; break; } } } else { mLastTouchDownIndex = childIndex; } mLastTouchDownX = ev.getX(); mLastTouchDownY = ev.getY(); newTouchTarget = addTouchTarget(child, idBitsToAssign); alreadyDispatchedToNewTouchTarget = true; break; } // The accessibility focus didn't handle the event, so clear // the flag and do a normal dispatch to all children. ev.setTargetAccessibilityFocus(false); } // 判断子View能收到点击事件的条件 private static boolean canViewReceivePointerEvents(@NonNull View child) { return (child.mViewFlags &amp; VISIBILITY_MASK) == VISIBLE || child.getAnimation() != null; } 接下来分发事件到子View，如果子View能收到点击事件，并且点击事件在子View的范围之内，这里判断子View能否收到点击事件的条件在于它是否可见，或子View的mCurrentAnimation不为null。事件交由子View去处理，如果子View处理了该次事件，则会通过addTouchTarget记录起来。确定了事件被消费后，就会结束循环。 if (mFirstTouchTarget == null) { // No touch targets so treat this as an ordinary view. handled = dispatchTransformedTouchEvent(ev, canceled, null, TouchTarget.ALL_POINTER_IDS); } else { // Dispatch to touch targets, excluding the new touch target if we already // dispatched to it. Cancel touch targets if necessary. TouchTarget predecessor = null; TouchTarget target = mFirstTouchTarget; while (target != null) { final TouchTarget next = target.next; if (alreadyDispatchedToNewTouchTarget &amp;&amp; target == newTouchTarget) { handled = true; } else { final boolean cancelChild = resetCancelNextUpFlag(target.child) || intercepted; if (dispatchTransformedTouchEvent(ev, cancelChild, target.child, target.pointerIdBits)) { handled = true; } if (cancelChild) { if (predecessor == null) { mFirstTouchTarget = next; } else { predecessor.next = next; } target.recycle(); target = next; continue; } } predecessor = target; target = next; } } 如果没有子View处理这次事件，则会执行super.dispatchTouchEvent，交给View的dispatchTouchEvent处理，代码如下： public boolean dispatchTouchEvent(MotionEvent event) { // If the event should be handled by accessibility focus first. if (event.isTargetAccessibilityFocus()) { // We don't have focus or no virtual descendant has it, do not handle the event. if (!isAccessibilityFocusedViewOrHost()) { return false; } // We have focus and got the event, then use normal event dispatch. event.setTargetAccessibilityFocus(false); } boolean result = false; if (mInputEventConsistencyVerifier != null) { mInputEventConsistencyVerifier.onTouchEvent(event, 0); } final int actionMasked = event.getActionMasked(); if (actionMasked == MotionEvent.ACTION_DOWN) { // Defensive cleanup for new gesture stopNestedScroll(); } if (onFilterTouchEventForSecurity(event)) { if ((mViewFlags &amp; ENABLED_MASK) == ENABLED &amp;&amp; handleScrollBarDragging(event)) { result = true; } //noinspection SimplifiableIfStatement ListenerInfo li = mListenerInfo; if (li != null &amp;&amp; li.mOnTouchListener != null &amp;&amp; (mViewFlags &amp; ENABLED_MASK) == ENABLED &amp;&amp; li.mOnTouchListener.onTouch(this, event)) { result = true; } if (!result &amp;&amp; onTouchEvent(event)) { result = true; } } if (!result &amp;&amp; mInputEventConsistencyVerifier != null) { mInputEventConsistencyVerifier.onUnhandledEvent(event, 0); } // Clean up after nested scrolls if this is the end of a gesture; // also cancel it if we tried an ACTION_DOWN but we didn't want the rest // of the gesture. if (actionMasked == MotionEvent.ACTION_UP || actionMasked == MotionEvent.ACTION_CANCEL || (actionMasked == MotionEvent.ACTION_DOWN &amp;&amp; !result)) { stopNestedScroll(); } return result; } 在View中的事件分发逻辑就比ViewGroup少多了，咱们挑重点看 ListenerInfo li = mListenerInfo; if (li != null &amp;&amp; li.mOnTouchListener != null &amp;&amp; (mViewFlags &amp; ENABLED_MASK) == ENABLED &amp;&amp; li.mOnTouchListener.onTouch(this, event)) { result = true; } if (!result &amp;&amp; onTouchEvent(event)) { result = true; } 在这里，可以看到View会先判断OnTouch事件，如果有OnTouchListener成功处理了这次事件，那么就不会执行onTouchEvent方法了。 至此，Android的事件分发机制就基本分析完了，总的来说，ViewGroup将事件分发给子View，并询问子View是否能处理这次事件，如果事件被拦截了，或者没有子View处理，则执行自己的onTouchEvent，并将dispatchTouchEvent的结果反馈给父类。 下面有几个疑问，想问下读者，也顺便提醒下自己 如果ACTION_DOWN事件没有被处理过，那么mFirstTouchTarget一定为null吗？ 可以看到在将事件分发给子View主要是通过dispatchTransformedTouchEvent方法的，在ViewGroup的dispatchTouchEvent中会遍历一次所有的子View，然后通过dispatchTransformedTouchEvent去询问子View是否有处理过事件，但是在dispatchTouchEvent的最后面可以看到，对于mFirstTouchTarget != null时，会再对它做一次事件分发，为什么要这么做呢？","link":"/2019/09/23/Android%E4%BA%8B%E4%BB%B6%E5%88%86%E5%8F%91%E6%9C%BA%E5%88%B6part2/"},{"title":"Android存储系统","text":"Android中的存储目录分为三块，内部存储，外部存储，系统存储目录 内部存储对于设备之每一个安装的APP都会在data/data/packagename/xxx目录下创建与之对应的文件夹，默认只能被此APP访问，当应用被卸载时，内部存储中的文件也会被删除。 根据手机厂商的不同，路径可能为 data/data/packagename/xxx data/user/0/packagename/xxx 获取方法 context.getFileDir(); // data/data/packagename/files context.getCacheDir(); // data/data/packagename/cache 当内存不足时会被优先删除 外部存储分为两部分 SD卡，应用被卸载后， 扩展卡内存，在APP被卸载后，这些文件也会被删除 文件路径为 扩展卡外部存储的路径 /storage/emulated/0/Android/data/packagename/xxx SD卡外部存储的路径 /storage/extSdCard/Android/data/packagename/xxx 获取方法 以下的type类型为 DIRECTORY_MUSIC 音乐目录DIRECTORY_PICTURES 图片目录DIRECTORY_MOVIES 电影目录DIRECTORY_DOWNLOADS 下载目录DIRECTORY_DCIM 相机拍照或录像文件的存储目录DIRECTORY_DOCUMENTS 文件文档目录 context.getExternalCacheDir(); // /storage/emulated/0/Android/data/packagename/cache context.getExternalFilesDir(String type); // /storage/emulated/0/Android/data/packagename/files context.getExternalStorageDirectory(); // /storage/emulated/0 context.getExternalStoragePublicDirectory(String type); // SD卡外部存储可以通过Environment获取，获取之前要先判断SD是否存在 if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) { File[] files = getExternalFilesDirs(Environment.MEDIA_MOUNTED); for (File file : files) { Log.e(\"file_dir\", file.getAbsolutePath()); } } 系统目录context.getRootDirectory(); // /system context.getDataDirectory(); // /data context.getDownloadCacheDirectory(); // /cache 参考一篇文章搞懂android存储目录结构作者：crazyandcoder","link":"/2020/04/01/Android%E5%AD%98%E5%82%A8/"},{"title":"Arouter 原理浅析","text":"前言想必大家都是用过arouter框架了，可以说arouter被广泛应用在组件化场景中，作为组件之间跳转的基石。在这篇中，我将主要分析arouter实现的原理，包括如何apt的部分以及使用时跳转的部分。 项目结构 与注解相关 arouter核心代码，读取apt生成的文件，api相关 apt注解相关，提取注解信息生成java文件 gradle 插件 ide插件 分析分析先从注解类开始入手，再分析apt提取注解信息逻辑，这部分包括android processor使用方法，以及java poet的基本使用方法，最后也是最简单的就是arouter-api这部分。 arouter基本注解类型 Autowired 变量相关(Param的替代，arouter跳转时携带的参数自动织入) Interceptor 路由拦截器注解 Route 路由注解 相关注解处理器 注解器处理注解生成java模板代码，到这里需要了解一下apt的基础知识，自定义注解处理器一般需要依赖下面两个库: implementation 'com.google.auto.service:auto-service:1.0-rc3' implementation 'com.squareup:javapoet:1.11.1' 第一个主要用于注册自定义的注解处理器的，其本身也是一个注解处理器，一般来说注册自定义注解器需要将注解器的绝对路径写入如下目录结构的文件中 而第二个库主要是用于生成java文件的，apt与javapoet分章再讲，先看看arouter这几个注解的逻辑 @Override public boolean process(Set&lt;? extends TypeElement> set, RoundEnvironment roundEnvironment) { if (CollectionUtils.isNotEmpty(set)) { try { // 获取所有被Autowired注解的element categories(roundEnvironment.getElementsAnnotatedWith(Autowired.class)); // 生成模板java文件，详情可以去看arouter源码 generateHelper(); } catch (Exception e) { logger.error(e); } return true; } return false; } /** * 例子 * s1被@Autowired注解，它的enclosingElement就是 A, parentAndChild收集的就是A中所有被 Autowired 注解的element **/ class A { @Autowired String s1; @Autowired String s2; } InterceptorProcessor/RouteProcessor的处理逻辑则差不太多，都是先获得相应的注解类，然后生成java模板代码。 模板代码的调用模板代码的调用逻辑在arouter-api中，所有的路由/拦截器信息都存在warehouse中，我们使用Arouter时，首先需要调用 Arouter.init(applicaiotn); protected static synchronized boolean init(Application application) { mContext = application; LogisticsCenter.init(mContext, executor); logger.info(Consts.TAG, \"ARouter init success!\"); hasInit = true; mHandler = new Handler(Looper.getMainLooper()); return true; } 模板代码的读取逻辑就在LogisticsCenter中，可以看到arouter通过DexFile读取到对应包名，筛选出com.alibaba.android.arouter.routes目录下route文件的路径，缓存在sharePeferences中，最后通过反射加载class文件缓存至warehouse中。 ARouter.getInstance().build(\"/test/activity2\").navigation(); 一般使用上面的方法进行ARouter跳转，逻辑大概是通过path在RouteMetaData中找到相关联的类信息存储在postcard对象中，最后在_ARoute中实现跳转逻辑，如果路由地址对应的是Activity，执行的就是ActivityCompat.startActivity/ActivityCompat.startActivityForResult. 结束语arouter的实现逻辑差不多就分析完了，总的来说就是编译时提取注解信息，生成java模板代码，难点可能在于对apt/javapoet我们并不是非常熟练，这两部分需要自己亲自实践一下才能熟悉它们的api，因此我准备重新开一章具体实践一下。感兴趣的朋友可以继续关注一下。","link":"/2019/12/08/Arouter/"},{"title":"Android多渠道打包及加固方案","text":"前言Android多渠道打包已经是老生常谈的问题了，各个大厂也先后开源了自己的打包方案，为我们开发者带来不少便捷。今天我就来谈谈美团的Walle，我在项目中也正是用到了它，也算做个总结和备忘吧。本篇中会提及Walle的基本使用方法以及如何在项目中配置加固使用，当然，最后也稍微会从源码的角度去分析一下这个方案的原理。那么，现在开始吧。 如何使用参考Walle项目Github首页，操作如下：在工程目录引入 buildscript { dependencies { classpath 'com.meituan.android.walle:plugin:1.1.6' } } 在app目录下引入 apply plugin: 'walle' dependencies { // 用于读取渠道号 compile 'com.meituan.android.walle:library:1.1.6' } 配置信息呢，可以参考官方说明，我这就简单记录下(copy)了 walle { // 指定渠道包的输出路径 apkOutputFolder = new File(\"${project.buildDir}/outputs/channels\"); // 定制渠道包的APK的文件名称 apkFileNameFormat = '${appName}-${packageName}-${channel}-${buildType}-v${versionName}-${versionCode}-${buildTime}.apk'; // 渠道配置文件 一个渠道占一行 channelFile = new File(\"${project.getProjectDir()}/channel\") } 不要忘记获取渠道信息 val channel = WalleChannelReader.getChannel(context) UMConfigure.init(this, UMENG_APP_KEY, channel, UMConfigure.DEVICE_TYPE_PHONE, \"\") 接下来只需要在gradle任务执行channelRelease或是执行 gradlew clean assembleReleaseChannels 渠道包就能生成在你指定的目录下面了。 但是这样操作完之后就没问题了吗？显然不是。通常我们发布自己的应用之前，还需要进行应用加固(360或是乐固，本文用的是乐固)，加固后会清除apk的签名和渠道信息，需要重新签名然后写入渠道信息。因此，打渠道变成了如下流程： 要满足上面的操作，项目中walle的配置显然就不太合适了，幸亏walle团队也有提供命令行工具walle-cli供我们自行打包，为了方便，我自己写了个简单的脚本，自动上传到乐固加固然后进行签名写入渠道信息，具体可以参考一下autoReinforce的项目说明。 源码分析有几个问题想问下大家。 渠道信息写在哪里了呢？为什么写在这个位置呢？ 渠道信息是如何进行读写操作的呢？ 第一个问题很简单啦，文档上也说了写在了Apk中的APK Signature Block区块，如下图，之所以写在这个位置是因为v2不会对该区域进行校验。 在payload_reader可以找到写入渠道的逻辑，在讲述逻辑之前，我们首先要了解一下EOCD(End of Centtal Directory)的结构： offset Bytes Description 0 4 End of central directory signature = 0x06054b50 4 2 Number of this disk 6 2 Disk where central directory starts 8 2 Number of central directory records on this disk 10 2 Total number of central directory records 12 4 Size of central directory (bytes) 16 4 Offset of start of central directory, relative to start of archive 20 2 Comment length (n) 22 n Comment 由于渠道信息是写在APK Signature Block，因此只要找到Center Directory的位置，那么往前就能找到Apk Signing Block的位置。在Walle中，通过循环找到魔数0x06054b50(假设Comment为空，通过增加Comment的长度，确定EOCD block的位置)，从而确定comment的长度，再将长度与Comment length对比，只要能确认Comment的长度，就能确认APK Signature Block的位置了。APK Signature Block结构如下表所示： offset Bytes Description @+0 8 block的长度(当前长度不计算在内) @+8 n ID-value值 @-24 8 block的长度 @-16 16 魔数”APK Sig Block 42” walle渠道信息就是写在ID-value中，在上一步中已经拿到Center Directory的offset，再向前24bytes，取8bytes，就能拿到APK Signature Block的长度了，注意这个长度是不包括前面8个bytes的，在walle中向前多偏移了8个bytes，取首尾block长度对比进行校验，代码片段如下： // Find the APK Signing Block. The block immediately precedes the Central Directory. if (centralDirOffset &lt; APK_SIG_BLOCK_MIN_SIZE) { throw new SignatureNotFoundException( \"APK too small for APK Signing Block. ZIP Central Directory offset: \" + centralDirOffset); } // 后面16bytes就是魔数啦 加上前面8bytes的black长度信息，24bytes // * 16 bytes: magic fileChannel.position(centralDirOffset - 24); final ByteBuffer footer = ByteBuffer.allocate(24); fileChannel.read(footer); footer.order(ByteOrder.LITTLE_ENDIAN); // 这里不是很清楚为什么要将魔数拆开来对比？ if ((footer.getLong(8) != APK_SIG_BLOCK_MAGIC_LO) || (footer.getLong(16) != APK_SIG_BLOCK_MAGIC_HI)) { throw new SignatureNotFoundException( \"No APK Signing Block before ZIP Central Directory\"); } // 尾部记录的block长度 final long apkSigBlockSizeInFooter = footer.getLong(0); if ((apkSigBlockSizeInFooter &lt; footer.capacity()) || (apkSigBlockSizeInFooter > Integer.MAX_VALUE - 8)) { throw new SignatureNotFoundException( \"APK Signing Block size out of range: \" + apkSigBlockSizeInFooter); } // 将总长度与头部记录的8bytes长度相加 final int totalSize = (int) (apkSigBlockSizeInFooter + 8); final long apkSigBlockOffset = centralDirOffset - totalSize; if (apkSigBlockOffset &lt; 0) { throw new SignatureNotFoundException( \"APK Signing Block offset out of range: \" + apkSigBlockOffset); } fileChannel.position(apkSigBlockOffset); final ByteBuffer apkSigBlock = ByteBuffer.allocate(totalSize); fileChannel.read(apkSigBlock); apkSigBlock.order(ByteOrder.LITTLE_ENDIAN); // 头部和尾部的长度杜比校验 final long apkSigBlockSizeInHeader = apkSigBlock.getLong(0); if (apkSigBlockSizeInHeader != apkSigBlockSizeInFooter) { throw new SignatureNotFoundException( \"APK Signing Block sizes in header and footer do not match: \" + apkSigBlockSizeInHeader + \" vs \" + apkSigBlockSizeInFooter); } // 拿到APK Signing Block了 再来看看ID-value区域结构 Bytes Description 8 序列长度n(不包括其本身) 4 序列id n-4 内容 了解了ID-value区域结构那么再贴一下获取custom ID-value的代码 // APK Sig Block 中的ID-value区域 final ByteBuffer pairs = sliceFromTo(apkSigningBlock, 8, apkSigningBlock.capacity() - 24); final Map&lt;Integer, ByteBuffer> idValues = new LinkedHashMap&lt;Integer, ByteBuffer>(); // keep order int entryCount = 0; while (pairs.hasRemaining()) { entryCount++; if (pairs.remaining() &lt; 8) { throw new SignatureNotFoundException( \"Insufficient data to read size of APK Signing Block entry #\" + entryCount); } // 获取总长度 8bytes final long lenLong = pairs.getLong(); if ((lenLong &lt; 4) || (lenLong > Integer.MAX_VALUE)) { throw new SignatureNotFoundException( \"APK Signing Block entry #\" + entryCount + \" size out of range: \" + lenLong); } final int len = (int) lenLong; // id开始的位置 final int nextEntryPos = pairs.position() + len; if (len > pairs.remaining()) { throw new SignatureNotFoundException( \"APK Signing Block entry #\" + entryCount + \" size out of range: \" + len + \", available: \" + pairs.remaining()); } // 获取id 4bytes final int id = pairs.getInt(); idValues.put(id, getByteBuffer(pairs, len - 4)); pairs.position(nextEntryPos); } 至此就分析完了如何在APK中去读取插入的渠道信息，顺带了解了一下APK包的结构。最后过一下如何写入渠道信息的吧，流程如下： 通过commentLength\\centralDirStartOffset\\apkSigningBlockAndOffset找到IdValues的位置 在IdValues block中找到V2签名的位置，判断是否已经签名 判断是否使用V3签名，如果有将长度补成4096的倍数(V3签名会校验) 写入渠道 结语从多渠道打包，引申出了Apk的签名V2签名逻辑(V1类似，但是是放在EOCD的Comment中)，Apk(Zip)包的结构等问题。这里只是简单的做下自我总结，如有疑问欢迎留言，当然你也可以选择去看看官方的文档和大神们的博客。 参考 带你了解腾讯开源的多渠道打包技术 VasDolly源码解析 by 鸿洋 APK文件结构详解 Meituan-Dianping/walle Tencent/VasDolly","link":"/2019/09/25/Android%E5%A4%9A%E6%B8%A0%E9%81%93%E6%89%93%E5%8C%85%E5%8F%8A%E5%8A%A0%E5%9B%BA%E6%96%B9%E6%A1%88/"},{"title":"Android Jetpack系列其二livedata","text":"1. livedata实现原理 2. livedata实现双向绑定 前言livedata是被观察者的持有类，并能感应生命周期。此篇文章重在分析两点 livedata如何实现观察者模式的 livedata是如何感知数据流的变化的 livedata是如何感知lifecycleOwner的生命周期的 使用与分析livedata一般是配合viewmodel使用的，首先看看下面的使用案例 class StoreViewModel: ViewModel { // 初始化 val articles: MutableLiveData&lt;MutableList&lt;Article>> = MutableLiveData() fun loadArticles(page: Int) { // 网络请求应放在对应repository中，这里为了方便说明 CoroutineScope(Dispatchers.IO).launch { val articlesWrapper = apiCenter().homeArticles(page.toString()) // 从服务器获取数据 articles.postValue(articlesWrapper.data.datas.toMutableList()) } } } class HomeFragment : BaseFragment() { fun initialized() { vm.articles.observe(this, Observer&lt;MutableList&lt;Article>> { // 通知UI更新 }) } } 接下来看看，在livedata内部是如何感知数据流变化的 // livedata的构造方法 public LiveData(T value) { mData = value; mVersion = START_VERSION + 1; } public LiveData() { mData = NOT_SET; mVersion = START_VERSION; } // 其中mData就是存储的数据了，version可以看做存储数据的当前版本 protected void postValue(T value) { boolean postTask; synchronized (mDataLock) { postTask = mPendingData == NOT_SET; mPendingData = value; } if (!postTask) { return; } ArchTaskExecutor.getInstance().postToMainThread(mPostValueRunnable); } // 发送数据到主线程，如果在主线程执行完任务之前postValue多次，那么只会分发最后一次的value // ArchTaskExecutor.getInstance().postToMainThread其实就是调用主线程的Handler将value传递到主线程 private final Runnable mPostValueRunnable = new Runnable() { @Override public void run() { Object newValue; synchronized (mDataLock) { newValue = mPendingData; mPendingData = NOT_SET; } //noinspection unchecked setValue((T) newValue); } }; @MainThread protected void setValue(T value) { assertMainThread(\"setValue\"); mVersion++; mData = value; dispatchingValue(null); } // 在这里会给mData重新赋值，然后做分发 // 在MutableLiveData中的setValue其实就是调用这个方法，在主线程中如果要直接给livedata赋值，可以直接调用此方法 // 再来看看livedata内部的观察者 private SafeIterableMap&lt;Observer&lt;? super T>, ObserverWrapper> mObservers = new SafeIterableMap&lt;>(); // 它其实是个双向列表 有如下优点 // 1.直接移动指针插入且无需执行hash算法效率高 // 2.可以一边遍历一遍删除元素而不会引起ConcurrentModifiedException // 3.使用双向链表存储数据比HashMap(java8)更节省空间 // 向livedata添加一个观察者 @MainThread public void observe(@NonNull LifecycleOwner owner, @NonNull Observer&lt;? super T> observer) { assertMainThread(\"observe\"); if (owner.getLifecycle().getCurrentState() == DESTROYED) { // ignore return; } LifecycleBoundObserver wrapper = new LifecycleBoundObserver(owner, observer); // 如果Map中不存在就放置进去并返回Null，如果存在直接拿出 ObserverWrapper existing = mObservers.putIfAbsent(observer, wrapper); if (existing != null &amp;&amp; !existing.isAttachedTo(owner)) { throw new IllegalArgumentException(\"Cannot add the same observer\" + \" with different lifecycles\"); } if (existing != null) { return; } owner.getLifecycle().addObserver(wrapper); } // LifecycleBoundObserver 生命周期边界的观察者 // LifecycleBoundObserver 它既是livedata事件的观察者又是生命周期变化的观察者，换句话来说，它既能感知livedata数据流的变化也能感知lifecycleOwner生命周期的变化 // 它被添加到了mObservers中也被添加到了LifecycleRegistry的mObserverMap: FastSafeIterableMap中 // 再来看看livedata是如何将数据变化下发到每一个观察者的 // 如果传值就是通知指定的observer，传Null就是通知所有的observer void dispatchingValue(@Nullable ObserverWrapper initiator) { if (mDispatchingValue) { mDispatchInvalidated = true; return; } mDispatchingValue = true; do { mDispatchInvalidated = false; if (initiator != null) { considerNotify(initiator); initiator = null; } else { for (Iterator&lt;Map.Entry&lt;Observer&lt;? super T>, ObserverWrapper>> iterator = mObservers.iteratorWithAdditions(); iterator.hasNext(); ) { considerNotify(iterator.next().getValue()); if (mDispatchInvalidated) { break; } } } } while (mDispatchInvalidated); mDispatchingValue = false; } // 这里跳过分析SafeIterableMap，FastSafeIterableMap，先把它们当作普通的迭代器，着重看下considerNotify private void considerNotify(ObserverWrapper observer) { if (!observer.mActive) { return; } // Check latest state b4 dispatch. Maybe it changed state but we didn't get the event yet. // we still first check observer.active to keep it as the entrance for events. So even if // the observer moved to an active state, if we've not received that event, we better not // notify for a more predictable notification order. if (!observer.shouldBeActive()) { observer.activeStateChanged(false); return; } if (observer.mLastVersion >= mVersion) { return; } observer.mLastVersion = mVersion; //noinspection unchecked observer.mObserver.onChanged((T) mData); } // 前面说了，这里的ObserverWrapper的实例是LifecycleBoundObserver // 通知观察者之前首先会检查lifecycleOwner的生命周期然后再检测数据的版本，都符合要求才会通知数据更新 到这里，livedata内部数据流动与感知的过程已大体分析完成了，它内部用SafeInterableMap作为观察者的容器，在数据发生变化的时候分发给所有的观察者，在lifecycleOwner生命周期发生变化时也会通过LifecycleBoundObserver的onStateChanged通知数据分发。 梳理了一下流程图： livedata实际应用livedata事件总线简单实现import androidx.annotation.MainThread import androidx.lifecycle.LifecycleOwner import androidx.lifecycle.MutableLiveData import androidx.lifecycle.Observer import java.lang.Exception class LiveDataBus private constructor() { private val mLock = Object() companion object { val instance: LiveDataBus = LiveDataBus() } private val bus: HashMap&lt;String, BusLiveData&lt;Any>> by lazy { HashMap&lt;String, BusLiveData&lt;Any>>() } fun subscribe(owner: LifecycleOwner, observer: Observer&lt;Any>, event: String) { if (bus.containsKey(event)) { val wrapper = BusLiveDataWrapper(observer) val liveData = bus[event] if (liveData?.alreadySubmit == false) { wrapper.scrapPreEvent = true liveData.alreadySubmit = true } bus[event]?.observe(owner, wrapper) } } fun postEvent(event: String, addition: Any) { if (bus.containsKey(event)) { bus[event]?.postValue(addition) } else { synchronized(mLock) { bus[event] = BusLiveData(addition) } } } @MainThread fun setEvent(event: String, addition: Any) { if (bus.containsKey(event)) { bus[event]?.value = addition } else { bus[event] = BusLiveData(addition) } } inner class BusLiveData&lt;T>(t: T) : MutableLiveData&lt;T>(t) { var alreadySubmit: Boolean = false } inner class BusLiveDataWrapper&lt;T> constructor( private val observer: Observer&lt;T>, var scrapPreEvent: Boolean = false ) : Observer&lt;T> { override fun onChanged(t: T) { if (scrapPreEvent) { scrapPreEvent = true return } try { observer.onChanged(t) } catch (e: Exception) { // catch ClassCastException etc. e.printStackTrace() } } } } 结语最后，做下总结，livedata的大致流程已经分析完了，但是比较重要的类LifecycleRegistry只是一笔带过了没有做分析，它是如何将生命周期变化事件分发到订阅者的呢？另外还有两个比较重要的数据结构FastSafeIterableMap和SafeIterableMap，在这里先记录一下啦，以后再填上吧。🖖 参考 LiveData Overview by Android Developers 用LiveDataBus替代RxBus、EventBus——Android消息总线的演进之路 by 美团技术团队 海亮","link":"/2019/11/07/Jetpack-livedata/"},{"title":"Fragment原理浅析","text":"前言Fragment在日常开发中非常的常用，一版都是配合ViewPager或FrameLayout使用，我们基本不用担心操作它attachToActivity，因为FragmentManager都帮我们处理好了。那么Fragment是如何绑定Activity的生命周期的呢？系统是如何将Fragment添加到视图层的呢？Fragment的回退栈又是什么呢？带着这些问题我们开始探索Fragment的源码吧。 基本操作首先来回顾一下，我们如何添加Fragment的: val fm = supportFragmentManager val ts = fm.beginTransaction() ts.add(fragment) ts.commit() 首先弄清几个概念： FragmentController 主要作用是绑定Activity与Fragment的生命周期，在FragmentActivity可以看到在每个生命周期函数，FragmentController都有做分发，最终交给了FragmentManager处理 FragmentManager Fragments的直接操作者，管理Fragment的内部状态以及添加\\移除\\隐藏\\显示Fragment等操作 FragmentTransaction 对Fragment操作的集合，各项操作会存储在Ops中，最终在FragmentManager中被执行 tips: FragmentTransaction本身是一个抽象类，它包含着一个内部类Op，根据其构造函数可以看出来这个类用于记录Fragment的操作，并将这一系列操作存储在mOps，其中四个抽象方法commit/commitAllowingStateLoss/commitNow/commitNowAllowingStateLoss就是我们经常放在最后执行的方法了。 // fm.beginTransaction() @NonNull @Override public FragmentTransaction beginTransaction() { return new BackStackRecord(this); } BackStackRecord继承了FragmentTransaction，可以看到在这个类中最终还是调用了FragmentManager的enqueueAction方法，将所有的操作加入执行队列中。并对需要记录Fragment回退栈的操作做如下处理： public int allocBackStackIndex(BackStackRecord bse) { synchronized (this) { if (mAvailBackStackIndices == null || mAvailBackStackIndices.size() &lt;= 0) { if (mBackStackIndices == null) { mBackStackIndices = new ArrayList&lt;BackStackRecord>(); } int index = mBackStackIndices.size(); if (DEBUG) Log.v(TAG, \"Setting back stack index \" + index + \" to \" + bse); // 将当前操作添加到数组中 mBackStackIndices.add(bse); return index; } else { // 找到一个可用的位置进行存储当前操作 int index = mAvailBackStackIndices.remove(mAvailBackStackIndices.size()-1); if (DEBUG) Log.v(TAG, \"Adding back stack index \" + index + \" with \" + bse); mBackStackIndices.set(index, bse); return index; } } } 最终调用了FragmentManager的enqueueAction/execSingleAction： public boolean execPendingActions() { // 校验准备工作 ensureExecReady(true); boolean didSomething = false; // 初始化数据源 while (generateOpsForPendingActions(mTmpRecords, mTmpIsPop)) { mExecutingActions = true; try { removeRedundantOperationsAndExecute(mTmpRecords, mTmpIsPop); } finally { // 清除执行程序 cleanupExec(); } didSomething = true; } updateOnBackPressedCallbackEnabled(); // 等待加载延迟的Fragment doPendingDeferredStart(); burpActive(); return didSomething; } public void execSingleAction(OpGenerator action, boolean allowStateLoss) { if (allowStateLoss &amp;&amp; (mHost == null || mDestroyed)) { // This FragmentManager isn't attached, so drop the entire transaction. return; } ensureExecReady(allowStateLoss); if (action.generateOps(mTmpRecords, mTmpIsPop)) { mExecutingActions = true; try { removeRedundantOperationsAndExecute(mTmpRecords, mTmpIsPop); } finally { cleanupExec(); } } updateOnBackPressedCallbackEnabled(); doPendingDeferredStart(); burpActive(); } 无论是执行execPendingActions还是execSingleAction，其核心方法还是removeRedundantOperationsAndExecute，这个方法可以移除冗余的操作，举个例子，如果两个事务一起执行，一个用于添加FragmentA，一个用于将FragmentA替换成FragmentB，实际上只有FragmentB会被添加，无法感应到FragmentA的创建/销毁生命周期。这个就是移除冗余操作的副作用了，Fragment的状态不会如预想那样变化。疑问，这个方法是如何去除冗余操作的呢？ // 移除冗余的回退栈操作再执行，需要设置setReorderingAllowed(true) private void removeRedundantOperationsAndExecute(ArrayList&lt;BackStackRecord> records, ArrayList&lt;Boolean> isRecordPop) { // 省略... final int numRecords = records.size(); int startIndex = 0; for (int recordNum = 0; recordNum &lt; numRecords; recordNum++) { final boolean canReorder = records.get(recordNum).mReorderingAllowed; // 所有事务如果设置了setReorderingAllowed(true)则全部跳过在最后一起执行 if (!canReorder) { // execute all previous transactions // 如果中间有事务A没有设置setReorderingAllowed(true)，则从startIndex到事务A会被一起执行 if (startIndex != recordNum) { executeOpsTogether(records, isRecordPop, startIndex, recordNum); } // execute all pop operations that don't allow reordering together or one add operation // 上述注释说明此处执行所有不允许一起排序的pop操作 // 在BackStackRecord中isRecordPop都为false，在PopBackStackState中isRecordPop都为true，这两个类分别对应着入栈和出栈，且仅当BackStackRecord设置了addToBackStack后才会被记录 int reorderingEnd = recordNum + 1; if (isRecordPop.get(recordNum)) { while (reorderingEnd &lt; numRecords &amp;&amp; isRecordPop.get(reorderingEnd) &amp;&amp; !records.get(reorderingEnd).mReorderingAllowed) { reorderingEnd++; } } executeOpsTogether(records, isRecordPop, recordNum, reorderingEnd); startIndex = reorderingEnd; recordNum = reorderingEnd - 1; } } if (startIndex != numRecords) { executeOpsTogether(records, isRecordPop, startIndex, numRecords); } } 接着往下看executeOps private static void executeOps(ArrayList&lt;BackStackRecord> records, ArrayList&lt;Boolean> isRecordPop, int startIndex, int endIndex) { for (int i = startIndex; i &lt; endIndex; i++) { final BackStackRecord record = records.get(i); final boolean isPop = isRecordPop.get(i); if (isPop) { record.bumpBackStackNesting(-1); boolean moveToState = i == (endIndex - 1); // 执行PopBackStackState record.executePopOps(moveToState); } else { record.bumpBackStackNesting(1); // 执行BackStackRecord record.executeOps(); } } } 然后是BackStackRecord的executeOps，最终这些ops由FragmentManager处理，将Fragment添加至mAdded或者从mAdded中移除，并对Fragment的内部状态进行修改。 最后也是最重要的方法moveToState，它主要负责修改Fragment的生命周期状态，在这我们可以看到Fragment是如何被添加至容器中的，在此Fragment中内部状态通过FragmentManger更新。 case Fragment.CREATED: //省略... f.mContainer = container; f.performCreateView(f.performGetLayoutInflater(f.mSavedFragmentState), container, f.mSavedFragmentState); if (f.mView != null) { f.mInnerView = f.mView; f.mView.setSaveFromParentEnabled(false); if (container != null) { // 将fragment的视图添加到宿主的容器中 container.addView(f.mView); } if (f.mHidden) { f.mView.setVisibility(View.GONE); } // 省略... } else { f.mInnerView = null; } // 省略... 至此，文章开始的疑问差不多都解决了，最后再梳理一下Fragment初始化流程。流程图大体如下： 结语Fragment的逻辑复杂，如果仅仅是靠读源码，是无法理清其复杂的逻辑关系的。此文的目的只是对Fragment做一次简单的探索，弄清楚它是如何被添加到视图的，如何去感知Activity的生命周期的，至于它的高级用法以及使用注意事项将会发布在其后的文章。","link":"/2019/09/29/Fragment%E5%8E%9F%E7%90%86%E6%B5%85%E6%9E%90/"},{"title":"Kotlin作用域函数(Scope Functions)","text":"前言Kotlin中有5种作用域函数，分别是： let, run, with, apply, and also 它们并没有任何特性，但是使用他们可以让我们的代码更加简洁，具备更好的可读性。我们可以在这找到它们的源码。下面我将分析这些方法的区别。 分析可以看到其实文档上已经有说明了，它们之间的区别在于： 引用上下文的方式 返回值 每个作用域函数使用两种访问上下文对象的方式之一：作为lambda接收器（this）或作为lambda自变量（it）。两者都提供相同的功能，因此我将描述在每种情况下的利弊，并提供有关其用法的建议。 thisrun, with, apply通过关键字this将上下文作为lambda的接收器。因此，在其lambda中，该对象的用法跟在普通类函数中一样。在大多数情况下，可以省略this直接使用接收器对象的成员变量，从而使代码更加简洁。但是如果省略了this，就很难区分出接收器对象的成员变量和外部变量或方法。因此，如果在lambda中操作对象，像是调用它的方法或是给属性赋值，推荐使用这三种作用域函数。 itlet, also将上下文对象作为lambda表达式的参数。如果在作用域中没有定义参数名，则默认为it。it比this更短，使用it的表达式更加易读。但是在调用对象方法和参数时，不能像this一样隐式调用。因此，当对象被用作方法参数时，推荐使用这两种作用域函数。 返回值 apply, also 返回上下文对象 let, run, with 返回lambda表达式的结果 如何选择使用为了更方便我们选择使用，官方给出了不少示例 letlet 可以被用在在调用链的结果上执行一个或者多个方法。 val numbers = mutableListOf(\"one\", \"two\", \"three\", \"four\", \"five\") numbers.map { it.length }.filter { it > 3 }.let { println(it) // and more function calls if needed } 如果代码块中只有一个方法，并将it作为参数，可以将lambda简写成(::) val numbers = mutableListOf(\"one\", \"two\", \"three\", \"four\", \"five\") numbers.map { it.length }.filter { it > 3 }.let(::println) let经常被用在执行non-null values的代码块。要对非空对象进行操作，需要使用安全操作符?. val str: String? = \"Hello\" //processNonNullString(str) // compilation error: str can be null val length = str?.let { println(\"let() called on $it\") processNonNullString(it) // OK: 'it' is not null inside '?.let { }' it.length } with官方建议使用with不返回结果(“with this object, do the following.”)，如下： val numbers = mutableListOf(\"one\", \"two\", \"three\") with(numbers) { println(\"'with' is called with argument $this\") println(\"It contains $size elements\") } run当你的lambda表达式中含有对象的初始化和返回值的计算时run就很有用了。 val service = MultiportService(\"https://example.kotlinlang.org\", 80) val result = service.run { port = 8080 query(prepareRequest() + \" to port $port\") } // the same code written with let() function: val letResult = service.let { it.port = 8080 it.query(it.prepareRequest() + \" to port ${it.port}\") } apply主要用作操作接收对象的成员，最典型的例子就是对象的配置。可以理解成”apply the following assignments to the object”。 val adam = Person(\"Adam\").apply { age = 32 city = \"London\" } 将接收对象作为返回值，你能很容易的将apply置入调用链中做更为复杂的处理。 alsoalso适用于将上下文对象作为参数的操作。also可以用作不改变对象的额外操作，像是打印日志或打印调试信息。通常，你可以从调用链中移除also而不会破坏程序原有的逻辑。可以将also理解成”and also do the following”。 总结可以参考下面的流程图 官方给出的对比表格： Function Object reference Return value Is extension function let it Lambda result Yes run this Lambda result Yes run - Lambda result No: called without the context object with this Lambda result No: takes the context object as an argument apply this Context object Yes also it Context object Yes 一句话总结： 对非空对象执行lambda：let 将表达式作为局部变量引入：let 对象配置：apply 对象配置并计算结果：run 需要表达式的运行语句：no-extension run 额外的操作：also 将对象的调用方法分组：with 总结语尽管作用域方法可以使代码更为简洁，但是请避免过度使用它：这样会减少代码的可读性并且可能导致错误。避免嵌套作用域函数，链式调用它们的时候要格外小心。 参考作用域函数kotlin standard function","link":"/2019/03/22/Kotlin%E5%9F%BA%E7%A1%80-%E4%BD%9C%E7%94%A8%E5%9F%9F%E5%87%BD%E6%95%B0/"},{"title":"Koltin委托属性","text":"委托模式在Kotlin中委托模式通过by关键字实现 interface Base { fun print() } class Derived(b: Base): Base by b 上述表达式表示b将代理Derived去实现interface Base的方法。 委托属性延迟属性(Lazy)Kotlin标准库中有很多有用的委托属性(delegates，代理属性)，像使用lazy方法创建一个对象，只有在第一次使用的时候会被初始化。 lazy的重载方法 public actual fun &lt;T> lazy(initializer: () -> T): Lazy&lt;T> = SynchronizedLazyImpl(initializer) public actual fun &lt;T> lazy(lock: Any?, initializer: () -> T): Lazy&lt;T> = SynchronizedLazyImpl(initializer, lock) public actual fun &lt;T> lazy(mode: LazyThreadSafetyMode, initializer: () -> T): Lazy&lt;T> = when (mode) { LazyThreadSafetyMode.SYNCHRONIZED -> SynchronizedLazyImpl(initializer) LazyThreadSafetyMode.PUBLICATION -> SafePublicationLazyImpl(initializer) LazyThreadSafetyMode.NONE -> UnsafeLazyImpl(initializer) } 由上可见，Lazy接口的实现类有三种SynchronizedLazyImpl，SafePublicationLazyImpl，UnsafeLazyImpl，前两者线程安全，但是实现方法有所不同，分别使用线程锁和原子类实现 private class SynchronizedLazyImpl&lt;out T>(initializer: () -> T, lock: Any? = null) : Lazy&lt;T>, Serializable { private var initializer: (() -> T)? = initializer @Volatile private var _value: Any? = UNINITIALIZED_VALUE // final field is required to enable safe publication of constructed instance private val lock = lock ?: this override val value: T get() { val _v1 = _value if (_v1 !== UNINITIALIZED_VALUE) { @Suppress(\"UNCHECKED_CAST\") return _v1 as T } return synchronized(lock) { val _v2 = _value if (_v2 !== UNINITIALIZED_VALUE) { @Suppress(\"UNCHECKED_CAST\") (_v2 as T) } else { val typedValue = initializer!!() _value = typedValue initializer = null typedValue } } } override fun isInitialized(): Boolean = _value !== UNINITIALIZED_VALUE override fun toString(): String = if (isInitialized()) value.toString() else \"Lazy value not initialized yet.\" private fun writeReplace(): Any = InitializedLazyImpl(value) } private class SafePublicationLazyImpl&lt;out T>(initializer: () -> T) : Lazy&lt;T>, Serializable { @Volatile private var initializer: (() -> T)? = initializer @Volatile private var _value: Any? = UNINITIALIZED_VALUE // this final field is required to enable safe publication of constructed instance private val final: Any = UNINITIALIZED_VALUE override val value: T get() { val value = _value if (value !== UNINITIALIZED_VALUE) { @Suppress(\"UNCHECKED_CAST\") return value as T } val initializerValue = initializer // if we see null in initializer here, it means that the value is already set by another thread if (initializerValue != null) { val newValue = initializerValue() if (valueUpdater.compareAndSet(this, UNINITIALIZED_VALUE, newValue)) { initializer = null return newValue } } @Suppress(\"UNCHECKED_CAST\") return _value as T } override fun isInitialized(): Boolean = _value !== UNINITIALIZED_VALUE override fun toString(): String = if (isInitialized()) value.toString() else \"Lazy value not initialized yet.\" private fun writeReplace(): Any = InitializedLazyImpl(value) companion object { private val valueUpdater = java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater( SafePublicationLazyImpl::class.java, Any::class.java, \"_value\" ) } } internal class UnsafeLazyImpl&lt;out T>(initializer: () -> T) : Lazy&lt;T>, Serializable { private var initializer: (() -> T)? = initializer private var _value: Any? = UNINITIALIZED_VALUE override val value: T get() { if (_value === UNINITIALIZED_VALUE) { _value = initializer!!() initializer = null } @Suppress(\"UNCHECKED_CAST\") return _value as T } override fun isInitialized(): Boolean = _value !== UNINITIALIZED_VALUE override fun toString(): String = if (isInitialized()) value.toString() else \"Lazy value not initialized yet.\" private fun writeReplace(): Any = InitializedLazyImpl(value) } 至于3者的区别，官方文档上已有说明，如果该值只在一个线程中计算，并且所有线程会看到相同的值就使用SynchronizedLazyImpl；如果该值在多个线程可以同时执行，那么使用SafePublicationLazyImpl；如果初始化发生与使用在同一个线程就使用UnsafeLazyImpl，它不会有任何线程安全的保证和开销。 可观察属性(Observable)在kotlin.properties.Delegates中，可以找到相关方法，分别是observable和vetoable，它们在被观察者的值发生改变时会执行回调，回调有三个值分别时被观察者的类型，旧值与新值；两者的区别在于，vetoable是否给被观察者赋值取决与回调函数的返回值。 var name: String by Delegates.observable(\"\") { property, oldValue, newValue -> } var age: String by Delegates.vetoable(\"\") { property, oldValue, newValue -> false } map代理(map delegate)暂时没有使用过这种代理。 class User(val map: Map&lt;String, Any?>) { val name: String by map val age: Int by map } 按照官方文档的例子，来看传入键值对，map代理会根据键值给相对的属性赋值，相关的实现方法如下 @kotlin.internal.InlineOnly public inline operator fun &lt;V, V1 : V> Map&lt;in String, @Exact V>.getValue(thisRef: Any?, property: KProperty&lt;*>): V1 = @Suppress(\"UNCHECKED_CAST\") (getOrImplicitDefault(property.name) as V1) @kotlin.jvm.JvmName(\"getOrImplicitDefaultNullable\") @PublishedApi internal fun &lt;K, V> Map&lt;K, V>.getOrImplicitDefault(key: K): V { if (this is MapWithDefault) return this.getOrImplicitDefault(key) return getOrElseNullable(key, { throw NoSuchElementException(\"Key $key is missing in the map.\") }) } 如果传入的map没有实现MapWithDefault接口，key不存在时会抛出NoSuchElementException异常，因此初始化map时，需要做类似如下操作： emptyMap&lt;String, String>().withDefault { key -> \"\" } 这样找不到相对应的key-value时，就会使用默认值了，实现方法如下： internal inline fun &lt;K, V> Map&lt;K, V>.getOrElseNullable(key: K, defaultValue: () -> V): V { val value = get(key) if (value == null &amp;&amp; !containsKey(key)) { return defaultValue() } else { @Suppress(\"UNCHECKED_CAST\") return value as V } } 使用的场景没有遇到过，但是有相关博客说，如果需要预定义keys的时候可以使用，相关博文会贴在下面 使用范例Shared Preferencesprivate inline fun &lt;T> SharedPreferences.delegate( defaultValue: T, key: String?, crossinline getter: SharedPreferences.(String, T) -> T, crossinline setter: Editor.(String, T) -> Editor ): ReadWriteProperty&lt;Any, T> { return object: ReadWriteProperty&lt;Any, T> { override fun getValue(thisRef: Any, property: KProperty&lt;*>) = getter(key?:property.name, defaultValue) override fun setValue(thisRef: Any, property: KProperty&lt;*>, value: T) = edit().setter(key?:property.name, value).apply() } } 有了如上方法我们就可以改造SharedPreferences了： // 存储Int fun SharedPreferences.int(def: Int=0, key: String?=null) = delegate(def, key, SharedPreferences::getInt, Editor::putInt) // 存储Long fun SharedPreferences.long(def: Long=0L, key: String?=null) = delegate(def, key, SharedPreferences::getLong), Editor::putLong) 使用 var sthInt by prefs.int() init { sthInt = 1 } // sthInt的getter和setter都被代理了，取值时实际上调用的是SharedPreferences::getInt，被赋值的同时，也通过Editor::putInt将值存入了SharedPreferences中。 更多的使用案例会逐一的添加的此篇中。 参考Kotlin delegates in Android development - Part1 by Fabio Collini Kotlin 委托属性","link":"/2019/10/24/KotlinDelegate/"},{"title":"Jenkins自动打包Android应用","text":"前言已经用Jenkins做过很多Android自动化打包的配置了，无奈记性不咋地，每配一次就要查一次资料，踩同样的坑，浪费不少时间和精力，更是被一些莫名其妙的问题折磨到抓狂，于是我决定在此把Jenkins的配置流程和遇到的坑整理、记录下来（其实早就想这么做了，但是懒癌晚期），方便以后做一些查阅。 基本步骤全局工具配置在系统管理中做全局工具配置，如下图配置 JAVA_HOME、GRADLE_HOME 指向JDK的安装目录和Gradle的解压目录，然后配置Jenkins的全局变量，这里我配置了python的路径，GRADLE_USER_HOME，这个变量用作gradle的缓存目录，还配置了ANDROID_HOME指向AndroidSdk的目录。 基础工程配置基础工程配置分为配置构建参数、源码管理、配置触发器、配置构建工具、构建后的一些操作 构建任务重命名 配置构建参数选择参数化构建过程&gt;选项参数 源码管理选择git作为版本控制工具 配置触发器解释下触发器的各个选项 触发远程构建 (例如,使用脚本)GitHub hook trigger for GITScm polling其他工程构建后触发定时构建Help for feature: 定时构建 轮询 SCM格式为 *第一个星号表示分钟，取值0~59第二个星号表示小时，取值0~23第三个星号表示一个月内的天数，取值1~31第四个星号表示第几个月，取值1~12第五个星号表示一周的第几天，取值0~7 多渠道打包配置配置参数 接入友盟//build.gradle 配置 productFlavors { yingyongbao { } huawei { } } productFlavors.all { flavor -> flavor.manifestPlaceholders = [UMENG_CHANNEL_VALUE: name] } 加固我在项目使用的是乐固加固，首先去下载他们的jar包。进入项目配置文件开始配置： 配置构建后操作，执行打包后再执行加固，如下图： 接下来转到加固项目的配置中，可以将下载下来的jar包做版本管理，也可以直接放在项目根目录中，配置构建步骤： 再签名然鹅加固完之后并没有结束，需要进行再签名， 加固过程不可避免的会破坏签名，因此加固后的包需重签名，未签名应用将无法顺利安装。 这里我是又另外建了一个项目，应该还有比较好的做法比如构建后执行什么的(需要另装插件) 主要看看签名脚本是怎么写的 import sys, os print('使用apksiger命令为apk签名') files = os.listdir('./') jks_file = None apk_file = None for file in files: if file.endswith('.jks'): jks_file = file elif file.endswith('.apk'): apk_file = file else: print(file) if jks_file == None or apk_file == None: print('当前目录不存在签名文件或者apk文件，请确认签名文件在当前目录下') sys.exit(1) file_name=apk_file zipalign_name=file_name.split('.apk')[0]+'_zipalign.apk' command='zipalign -v -p 4 {0} {1}'.format(file_name, zipalign_name) os.system(command) jks_name=jks_file key_alias = 'bonadeTravel' ks_pass = 'bonadetravel888' key_pass = 'bonadetravel888' apk_name=zipalign_name.split('.apk')[0]+'_signed.apk' command='apksigner sign --ks {0} --ks-key-alias {1} --ks-pass pass:{2} --key-pass pass:{3} --out {4} {5}'.format(jks_name, key_alias, ks_pass, key_pass, apk_name, zipalign_name) os.system(command) 执行构建脚本clean assemble${channel}${buildType} --stacktrace //如果需要打所有渠道包 assemble${buildType} --stacktrace 构建后的操作构建完成后的操作: 提取apk文件 上传到蒲公英 jenkins中生成二维码 通知测试人员 tips想修改一下apk文件输出目录，于是修改build.gradle applicationVariants.all { variant -> variant.outputs.each { output -> def outputFile = output.outputFile if (outputFile != null &amp;&amp; outputFile.name.endsWith('.apk')) { if(!outputFile.name.contains(\"debug\")){ def fileName = outputFile.name.replace(\".apk\", \"-${defaultConfig.versionName}.apk\") output.outputFile = new File(\"C:\\\\Users\\\\user\\\\Desktop\\\\apk\\\\${defaultConfig.versionName}\", fileName) } } } } 在4.0+gradle方法稍有不同 applicationVariants.all { variant -> variant.outputs.all { // 自定义输出路径 但是getPackageApplication()将在19年底被移除 variant.getPackageApplication().outputDirectory = new File(project.rootDir.absolutePath + File.separator + \"outputs\") outputFileName = \"AppName-${variant.flavorName}-${variant.buildType.name}-v${variant.versionName}_${time()}.apk\" } 最终版本 applicationVariants.all { variant -> variant.outputs.all { def newName def timeNow if (\"true\".equals(IS_JENKINS)) { timeNow = JENKINS_TIME variant.packageApplicationProvider.get().outputDirectory = new File(project.rootDir.absolutePath + File.separator + \"apks\") newName = \"xxx-v${APP_VERSION}-${timeNow}-${variant.buildType.name}.apk\" } else { timeNow = getDate() if (variant.buildType.name.equals('debug')) { newName = \"xxx-v${APP_VERSION}-debug.apk\" } else { newName = \"xxx-v${APP_VERSION}-${timeNow}-${variant.buildType.name}.apk\" } } outputFileName = \"${newName}\" } } 遇到的坑在jenkins中编译的时候报错找不到abc_ab_share_pack_mtrl_alpha.9.pngwtf没见过这种错误啊，我估摸着会不会是路径太长的原因，于是在gradle.properties中配置了android.buildCacheDir=F\\://androidCache，但是，并没有卵用，秉承着不解决问题不罢休的态度，我又浪费了一个下午。终于，在stackoverflow上，看到有个哥们提到在jenkins中设置GRADLE_USER_HOME这个环境变量，随便指向一个目录。然后就不报错了。我的内心是崩溃的，好吧，总算是解决了，但是为什么AndroidStudio下编译就不会报错呢。 com.sun.org.apache.xerces.internal.impl.io.MalformedByteSequenceException: 3 字节的 UTF-8 序列的字节 3 无效又碰到一个奇怪的问题，这个坑是databinding框架产生的，由于我是在linux上开发的，jenkins环境部署在本地的windows上，在xml中databinding的表达式中如果出现了中文字符，就会报编码错误，于是我只能硬着头皮修改布局文件，把中文字符移到资源文件中。 开启混淆后报错，proguard-rules.pro文件配置出错Execution failed for task ':app:transformClassesAndResourcesWithProguardForRelease'. 通过执行 gradlew --stacktrace task xxx 可以看到具体的报错信息，主要是不能混淆的文件没有忽略掉，逐个干掉就行了。 jenkins使用不了系统的环境变量配置一下jenkins的环境变量然后重启生效 jenkins控制台出现中文乱码jenkins环境变量中添加 key: LANG value: zh.CH.UTF-8 参考用apksigner进行批量签名的脚本乐固加固FAQ 结语上面记录的问题只不过是诸多问题的冰山一角，以后我遇到的jenkins相关的问题都会记录于此。想要熟练运用Android打包，看样子还是要深入研究一下gradle才行呐。","link":"/2018/04/28/jenkins%E8%87%AA%E5%8A%A8%E5%8C%96%E6%89%93%E5%8C%85/"},{"title":"Kotlin语法糖 Part3","text":"前言在前面的两篇文章中，我们了解到了： sealed when() with() inline function and reified type 在这章中，我会给大家分享我是如何使用Kotlin委托机制的。 Kotlin的委托机制Kotlin有一个内置的委托模式。在一些书中也提及委托模式是实现继承的一个很好的替代方式，在Kotlin使用它进行聚合非常容易： interface Navigable { val onNavigationClick: (()->Unit)? } interface Searchable { val searchText:String } class Component(navigation: Navigable, searchable: Searchable): Navigable by navigable, Searchabe by searchable 使用by关键字，即可委托navigation、searchable的所有行为。比起Java，Kotlin减少了大量的模板代码。如果你把interface标记为internal，你会发现编译不能通过 ‘public’ function exposes its ‘internal’ parameter type xxx Kotlin编译器不允许暴露模块的内部组件，如果想在不暴露Navigable，Searchable的前提下解决这个问题，你只需要做： 移除构造器 使用组合代替聚合 定义包含Navigable和Searchable方法名的ComponentInterface interface ComponentInterface { val onNavigationClick: (()->Unit)? var searchText: String } class Component: ComponentInterface { private val navigable: Navigable = NavigableImpl() private val searchable: Searchable = SearchableImpl() override val onNavigationClick: (()->Unit)? get() = navigable.onNavigationClick override var searchText: String = \"\" get() = searchable.searchText set(value) { field = value searchable.searchText = value } } 经过改造后，你发现代码从零模板的聚合变成了看上去很讨厌的组合方式。但是先别哭，Kotlin总能给你带来愉悦的编码体验。Kotlin不仅支持使用by关键字对指定对象进行方法委派，还具有委托属性的机制。你可能已经在使用lazy关键字初始化对象时接触到了它的这一机制了。 private val lazyProperty by lazy { \"\" } 怎么从使用lazy()上来改造上面组合的代码呢，请看代码： class ReferencedProperty&lt;T>(private val get: () -> T, private val set: (T) -> Unit = {}) { operator fun getValue(thisRef: Any?, property: KProperty&lt;*>): T = get() operator fun setValue(thisRef: Any?, property: KProperty&lt;*>, value: T) = set(value) } fun &lt;T> ref(property: KMutableProperty0&lt;T>) = ReferencedProperty(property::get, property::set) fun &lt;T> ref(property: KProperty0&lt;T>) = ReferencedProperty(property::get) ReferencedProperty用两个方法作为参数，并定义了两个函数： get函数返回泛型T set函数以T作为参数 getValue()调用get() setValue()调用set() 最重要的一点是你需要知道操作符用到了属性代理机制。在ReferencedProperty类下，你会发现两个返回ReferencedProperty的泛型方法，第一个用于var，第二个用于val。现在让我们用ref()简化代码 class Component : ComponentInterface { private val navigable: Navigable = NavigableImpl() private val searchable: Searchable = SearchableImpl() override val onNavigationClick by ref(navigable::onNavigationClick) override var searchText by ref(searchable::searchText) } 希望看完这三章你能有些许收获。 参考6 magic sugars that can make your Kotlin codebase happier — Part 3","link":"/2019/04/05/Kotlin%E8%AF%AD%E6%B3%95%E7%B3%96Part3/"},{"title":"Room原理浅析","text":"前言 Room是Google推出的数据库处理框架，Jetpack中的一员 版本号androidx.room:room-common:2.2.3 androidx.room:room-runtime:2.2.3 androidx.room:room-compiler:2.2.3 使用示例声明一个抽象类继承RoomDatabase，在这个类中主要是写一些getDao的方法，同时也需要用Database注解这个类，告知compiler这个数据库的实体类/版本号等信息，如下示例 @Database(entities=[Fruit::class,Meat::class],version=1) abstract class AppDataBase:RoomDatabase(){ abstract fun getFruitDao():FruitDao abstract fun getMeatDao():MeatDao } dao文件的声明如下 @Dao interface FruitDao{ @Insert(onConflict=OnConflictStrategy.REPLACE) fun insertFruit(fruit:Fruit) @Query(\"DELETE FROM fruit\") fun deleteFruit() @Query(\"SELECT*FROM fruit\") fun queryFruit():Fruit } 好了，通过下面的方法我们就能拿到database对象了，有了RoomDatabase就能操作dao对表做CRUD操作了。 Room.databaseBuilder(application,AppDataBase::class.java,DB_NAME).build() Room的使用流程大概如上，有如下几个疑问： RoomTestDataBase是个抽象类，抽象方法在哪实现的？ RoomTestDataBase内部的Dao是interface，内部的增删改查又是在哪实现的？ 创建Room Database流程 @NonNull public T build() { //noinspection ConstantConditions //预检测参数 省略... if (mFactory == null) { // SQLiteOpenHelper工厂类 创建SQLiteOpenHelper真正操作数据库 mFactory = new FrameworkSQLiteOpenHelperFactory(); } //DataBase构建参数 DatabaseConfiguration configuration = new DatabaseConfiguration(mContext, mName, mFactory, mMigrationContainer, mCallbacks, mAllowMainThreadQueries, mJournalMode.resolve(mContext), mRequireMigration, mMigrationsNotRequiredFrom); T db = Room.getGeneratedImplementation(mDatabaseClass, DB_IMPL_SUFFIX); // 初始化 RoomDataBaseOpenHelper db.init(configuration); return db; } // 由方法名可知在这里生成实现类 @NonNull static &lt;T, C> T getGeneratedImplementation(Class&lt;C> klass, String suffix) { final String fullPackage = klass.getPackage().getName(); String name = klass.getCanonicalName(); final String postPackageName = fullPackage.isEmpty() ? name : (name.substring(fullPackage.length() + 1)); final String implName = postPackageName.replace('.', '_') + suffix; //noinspection TryWithIdenticalCatches try { @SuppressWarnings(\"unchecked\") // 通过反射获取xxxDataBase_Impl，该类通过room-compiler生成 final Class&lt;T> aClass = (Class&lt;T>) Class.forName( fullPackage.isEmpty() ? implName : fullPackage + \".\" + implName); return aClass.newInstance(); } //省略 catch exceptions } 简单的分析一下上面代码逻辑 我们从Room.databaseBuilder().build()分析room是如何将数据库创建出来的，builder中的变量就是创建database所需的参数，在build()中进行了参数的预校验，最终调用Room.getGenratedImplementation()，拼接出类名AppDataBase_Imp，通过反射创建对象，而这个AppDataBase_Imp则是通过注解处理器自动生成的，它继承了抽象类AppDataBase，再来趴一下AppDataBase_Imp，在createOpenHelper函数中，它利用SupportSQLiteOpenHelper.Factory工厂类创建了SupportSQLiteOpenHelper，这个工厂类在建造者模式Room.databaseBuilder().build()中被初始化，真正调用的是FrameworkSQLiteOpenHelperFactory.create函数，创建了FrameworkSQLiteOpenHelper，在RoomDatabase使用的databaseOpenHelper也就是这个类了，其实FrameworkSQLiteOpenHelper是个代理类，它内部的OpenHelper继承了SQLiteOpenHelper，到此终于看到了熟悉的类型，我们直接使用SQLite通常也是直接写一个helper类直接继承SQLiteOpenHelper，而ROOM通过层层装饰省去了我们创建SQLiteOpenHelper的麻烦，最后用一张流程图总结ROOM创建database的过程。 指定Room schema的输出路径在我们使用room Database注解时，会发现有exportSchema属性，官方注释如下： /** * You can set the annotation processor argument ({@code room.schemaLocation}) to tell Room to * export the database schema into a folder. Even though it is not mandatory, it is a good * practice to have version history of your schema in your codebase and you should commit the * schema files into your version control system (but don't ship them with your app!). * &lt;p> * When {@code room.schemaLocation} is set, Room will check this variable and if it is set to * {@code true}, the database schema will be exported into the given folder. * &lt;p> * {@code exportSchema} is {@code true} by default but you can disable it for databases when * you don't want to keep history of versions (like an in-memory only database). * * @return Whether the schema should be exported to the given folder when the * {@code room.schemaLocation} argument is set. Defaults to {@code true}. */ boolean exportSchema() default true; 大概是说这个属性是控制是否输出schema的，建议大家将数据库的schema做版本控制，方便数据库的迁移和版本升级/降级。 在gradle可以配置schema的输出目录，具体代码如下 android{ ...//省略 defaultConfig { ... //省略 javaCompileOptions{ annotationProcessorOptions{ arguments=[\"room.schemaLocation\":\"$projectDir/schemas\".toString()] } } } } Room的版本迁移在开发过程中数据库的表结构可能会发生变化，在Room中如果你不做相应的处理，则会抛出异常并提示你A migration from old_version to new_version was required but not found，我们可以通过addMigrations()处理版本迁移中数据库的变动，也可以通fallbackToDestructiveMigration/fallbackToDestructiveMigrationOnDowngrade/fallbackToDestructiveMigrationFrom设置数据库在版本升级的时候，删除原表并创建新表，但是会导致原数据的丢失，因此，为了防止用户数据丢失，我们需要管理好自己数据库的版本，并在版本升级时处理好变动的数据。下面示范了Fruit表中新增字段后是如何做处理的 valversion1To2=object:Migration(1,2){ override fun migrate(database:SupportSQLiteDatabase){ database.execSQL(\"ALTER TABLE fruit ADD COLUMN test TEXT NOT NULL DEFAULT''\") } } 当遇到比较复杂的情况时，只要我们做好数据库的版本管理就都能很好的解决。 CRUD流程接下来看看ROOM的CRUD流程，我们可以从DAO入手，dao_Impl也是编译时生成的文件，看看FruitDao_Impl的insertFruit函数，如下所示 public void insertFruit(final Fruit fruit){ __db.assertNotSuspendingTransaction(); __db.beginTransaction(); try{ __insertionAdapterOfFruit.insert(fruit); __db.setTransactionSuccessful(); }finally{ __db.endTransaction(); } } 它对应的FruitDao函数 @Insert(onConflict = OnConflictStrategy.REPLACE) fun insertFruit(fruit: Fruit) 插入逻辑 public final void insert(T entity) { final SupportSQLiteStatement stmt = acquire(); try { bind(stmt, entity); // 绑定数据 stmt.executeInsert(); // 执行插入语句 } finally { release(stmt); } } 最终将调用的函数 // SQLiteProgram private void bind(int index, Object value) { // ...省略 mBindArgs[index - 1] = value; // 将数据存入 } // SQLiteStatement public long executeInsert() { acquireReference(); try { return getSession().executeForLastInsertedRowId( getSql(), getBindArgs(), getConnectionFlags(), null); } catch (SQLiteDatabaseCorruptException ex) { onCorruption(); throw ex; } finally { releaseReference(); } } 结语关于Room的原理和基本使用方法就介绍到这了，本来还想分析一下room-compiler的，但是感觉写下去篇幅会太长了。下节将借room-compiler总结一下annotation-processor的开发流程。","link":"/2019/03/21/Room%E5%8E%9F%E7%90%86%E6%B5%85%E6%9E%90/"},{"title":"Kotlin语法糖 Part1","text":"Kotlin给我们提供了大量的工具和语法糖让我们能够更为便利的去编程，让代码有更好的可读性和可扩展性。写更少的代码做更多的事，用这句话概括Kotlin和Java之间的差异一点都不为过。面对Kotlin这种能减轻我们工作量的工具，我们有什么理由不去学习它呢？我相信有效地使用Kotlin会对你的身心带来巨大的愉悦，在使用Kotlin的过程中，它的简洁和优雅的语法不断地给我带来惊喜，可能这也是Google使用它作为Android官方编程语言的原因吧。Kotlin的语法糖有很多，我至今也还在学习中，接下来我将用三篇文章的篇幅将目前我使用较多的介绍给大家。这篇文章是这个系列的第一章，在这张中我们主要来了解下密封类(sealed class)的用法。 密封类(sealed class)用sealed关键字修饰的类我们称之为密封类，在官方文档中是这么介绍的 密封类用来表示受限的类继承结构，当一个值为有限集中的类型、而不能有任何其他类型。 这是不是很枚举类很相似呢，我认为sealed class比枚举的用法更为灵活，每个枚举类只能存在一个实例，但是密封类的子类可以包含多个不同内部状态的实例。上代码 sealed class Response data class Success(val body: String): Response() data class Error(val code: Int, val message: String): Response() object Timeout: Response() sealed class 自身抽象，它不能直接实例化，但是可以有abstract成员。我们使用IntelliJ IDEA Kotlin Bytecode工具将上面的代码还原程Java代码。 1.Reveal Koltin Bytecode 2.Decompile Kotlin Bytecode to Java code 经过这几步，就可以开始阅读转换后Java代码了 public abstract class Response { private Response() { } // $FF: synthetic method public Response(DefaultConstructorMarker $constructor_marker) { this(); } } 你可能已经在想，seald classes专门为继承而生，因此他们是抽象的。但是，他们怎么会类似enums?下面是Kotlin编译器通过允许您使用Response类的子类作为(as case of)when（）函数的条件时给您带来巨大帮助的时候了。另外，kotlin提供了极大的灵活性(flexibility)，继承sealed class的对象可以是一个data class(数据类)或object fun sugar(response: Response) = when (response) { is Success -> ... is Error -> ... Timeout -> ... } 这样的代码看上去不仅仅是结构清晰，在使用它时，你甚至不用去做额外的强制转换，在条件语句的最后也不再需要else子句了，我们已经覆盖了所有的情况。 fun sugar(response: Response) = when (response) { is Success -> println(response.body) is Error -> println(\"${response.code} ${response.message}\") Timeout -> println(response.javaClass.simpleName) } 不使用sealed关键字的代码是怎样的？可以用IntelliJ IDEA Kotlin Bytecode转换成Java看下 public final void sugar(@NotNull Response response) { Intrinsics.checkParameterIsNotNull(response, \"response\"); String var3; if (response instanceof Success) { var3 = ((Success)response).getBody(); System.out.println(var3); } else if (response instanceof Error) { var3 = \"\" + ((Error)response).getCode() + ' ' + ((Error)response).getMessage(); System.out.println(var3); } else { if (!Intrinsics.areEqual(response, Timeout.INSTANCE)) { throw new NoWhenBranchMatchedException(); } var3 = response.getClass().getSimpleName(); System.out.println(var3); } } 可见使用Kotlin我们减少了多少代码量。 使用when()方法自由的排列组合接下来我们看看枚举类和when()的配合。 enum class Employee { DEV_LEAD, SENIOR_ENGINEER, REGULAR_ENGINEER, JUNIOR_ENGINEER } enum class Contract { PROBATION, PERMANENT, CONTRACTOR, } Employee枚举定义了Company中的所有角色，Contract枚举包含了所有类型的员工合同。通过这两个枚举的排列组合我们要返回正确的SafariBookAccess。 fun access(employee: Employee, contract: Contract): SafariBookAccess 然后用定义SafariBooksAccess sealed class SafariBookAccess data class Granted(val expirationDate: DateTime) : SafariBookAccess() data class NotGranted(val error: AssertionError) : SafariBookAccess() data class Blocked(val message: String) : SafariBookAccess() 在access()方法中做排列组合 fun access(employee: Employee, contract: Contract): SafariBookAccess { return when (employee) { SENIOR_ENGINEER -> when (contract) { PROBATION -> NotGranted(AssertionError(\"Access not allowed on probation contract.\")) PERMANENT -> Granted(DateTime()) CONTRACTOR -> Granted(DateTime()) } REGULAR_ENGINEER -> when (contract) { PROBATION -> NotGranted(AssertionError(\"Access not allowed on probation contract.\")) PERMANENT -> Granted(DateTime()) CONTRACTOR -> Blocked(\"Access blocked for $contract.\") } JUNIOR_ENGINEER -> when (contract) { PROBATION -> NotGranted(AssertionError(\"Access not allowed on probation contract.\")) PERMANENT -> Blocked(\"Access blocked for $contract.\") CONTRACTOR -> Blocked(\"Access blocked for $contract.\") } else -> throw AssertionError() } } emm，这样写不够简洁，上述代码存在以下问题： 过多的when()方法。可以用Pair避免嵌套(nesting) 改变枚举类参数的顺序，使用Pair&lt;Contract, Employee&gt;()提高可读性 将返回相同的case合并 改为单表达式函数(Single-Expression functions) 然后，我们来改造一下这段代码 fun access(contract: Contract, employee: Employee) = when (Pair(contract, employee)) { Pair(PROBATION, SENIOR_ENGINEER), Pair(PROBATION, REGULAR_ENGINEER), Pair(PROBATION, JUNIOR_ENGINEER) -> NotGranted(AssertionError(\"Access not allowed on probation contract.\")) Pair(PERMANENT, SENIOR_ENGINEER), Pair(PERMANENT, REGULAR_ENGINEER), Pair(PERMANENT, JUNIOR_ENGINEER), Pair(CONTRACTOR, SENIOR_ENGINEER) -> Granted(DateTime(1)) Pair(CONTRACTOR, REGULAR_ENGINEER), Pair(CONTRACTOR, JUNIOR_ENGINEER) -> Blocked(\"Access for junior contractors is blocked.\") else -> throw AssertionError(\"Unsupported case of $employee and $contract\") } 现在看上去是不是很简洁了，但是还能更加简洁： fun access(contract: Contract, employee: Employee) = when (contract to employee) { PROBATION to SENIOR_ENGINEER, PROBATION to REGULAR_ENGINEER -> NotGranted(AssertionError(\"Access not allowed on probation contract.\")) PERMANENT to SENIOR_ENGINEER, PERMANENT to REGULAR_ENGINEER, PERMANENT to JUNIOR_ENGINEER, CONTRACTOR to SENIOR_ENGINEER -> Granted(DateTime(1)) CONTRACTOR to REGULAR_ENGINEER, PROBATION to JUNIOR_ENGINEER, CONTRACTOR to JUNIOR_ENGINEER -> Blocked(\"Access for junior contractors is blocked.\") else -> throw AssertionError(\"Unsupported case of $employee and $contract\") } 希望这些语法糖能对你有所帮助，剩下的我们将在Part2中讲解。 转自 Piotr Ślesarew @ Medium 6 magic sugars that can make your Kotlin codebase happier — Part 1编写 snoopy@we1code.cn","link":"/2019/03/23/kotlin%E8%AF%AD%E6%B3%95%E7%B3%96Part1/"},{"title":"vps搭建ssr服务器","text":"前言发现最近一些搭建ssr服务器的教程都被迫下线了，心里慌的一匹，原先都是参照教程来搭建的，没有教程我可怎么办，赶紧备份一波。 vps服务器选择原先一直用搬瓦工，因为便宜啊，用了一年多ip被封了，花了将近10美元重置，一天不到又给我封了，遂换成vultr(1RMB一天)，这个比搬瓦工(9.99美元一年)贵上不少，但是好在能随时免费换ip，这个ip被封了，我再换一个。下面的服务商我就没用过了，先记录着，万一哪一天vultr也不好用了呢。 商家 价格(最低配) https://digital-vm.com $4/MONTHLY $41/YEARLY https://www.onevps.com $4/MONTHLY www.fastcomet.com $2.95/MONTHLY https://www.hostkvm.com $9.5/MONTHLY https://www.locvps.com 68RMB/MONTHLY https://zheye.io 88RMB/MONTHLY https://www.jwdns.com 88RMB/MONTHLY https://hxkvm.com 65RMB/MONTHLY https://www.gke.cc 65RMB/MONTHLY www.aoyouhost.com 48RMB/MONTHLY 注1：这里只进行价格对比，详细配置还需自行仔细查看注2：如果选择了vultr，一定要先测试一下服务器ip是否被墙了，然后再进行下面的操作，如果被墙了，请换一台服务器再试！ 部署(非新手向) 安装脚本 wget --no-check-certificate https://freed.ga/github/shadowsocksR.sh; bash shadowsocksR.sh 注：根据脚本提示选择密码，端口号等，最后请小心保存配置信息 安装锐速 留意看自己服务器所安装的系统，如果是centos6*64，执行如下命令： wget --no-check-certificate -O appex.sh https://raw.githubusercontent.com/hombo125/doubi/master/appex.sh && bash appex.sh install '2.6.32-642.el6.x86_64' 如果是centos7*64则需先更换系统内核 wget --no-check-certificate -O rskernel.sh https://raw.githubusercontent.com/hombo125/doubi/master/rskernel.sh && bash rskernel.sh 然后再安装锐速 yum install net-tools -y && wget --no-check-certificate -O appex.sh https://raw.githubusercontent.com/0oVicero0/serverSpeeder_Install/master/appex.sh && bash appex.sh install 配置信息如下图所示(其实不是很明白第一项为啥选n) 结束语到这里，所有流程都已经走完了，最后提醒大家所有的配置信息一定要妥善保存哟。 参考 用VPS搭建SSR服务器教程(写的真的很详细，新手小伙伴可以过去学习一下)","link":"/2019/09/21/vps%E6%90%AD%E5%BB%BAssr%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"Kotlin语法糖 Part2","text":"前言在第一章中，我们学会了如何使用sealed classes，以及when()配合Pair或Triple使用做多重条件判断。 在这一章中，我想跟大家分享一下with()和inline reified的基本使用。 使用with()函数with()函数位于Standard.kt，是Kotlin标准函数之一，大家可以看看，掌握好这些函数对于我们简化编程有很大的帮助，有时间我会另开一章分享我平时使用到它们的地方，当然也非常欢迎大家评论分享使用技巧。假设你从未使用过with()函数，我们可以先看看源码： inline fun &lt;T, R> with(receiver: T, block: T.() -> R): R Calls the specified function block with the given receiver as its receiver and returns its result. 大体的意思是调用receiver中的方法然后返回它的结果： val receiver: String = \"Fructos\" val block: String() -> Unit = { println(toUpperCase()) println(toLowerCase()) println(capitalize()) } val result: Unit = with&lt;String, Unit>(receiver, block) //简化一下代码 with(sugar) { println(toUpperCase()) println(toLowerCase()) println(capitalize()) } 在block中你可以调用到receiver的方法而且不需要任何限定符，在block的最后返回你需要的数据类型就可以了。在项目中我经常使用它在p层传递限定符像是view.show(),view.hide() interface View { fun show() fun hide() fun reset() fun clear() } class Presenter(private val view: View) { fun present(isFructos:Boolean) = with(view) { if(isFructos) { show() hide() } else { hide() clear() } } } inline reified我们先分析一下下面的代码 abstact class Item class MediaItem: Item() { val media = ... } class IconItem: Item() { val icon = ... } interface Renderer { fun render(view: View, item:Item) } class MediaItemRenderer: Renderer { override fun render(view: View, item: Item) { if(item !is MediaItem) { throw AssertionError(\"Item is not an instance of MediaItem\") } view.showMedia(item.media) view.reset() } } class IconItemRenderer: Renderer { override fun render(view: Viewm, item: Item) { if(item !is IconItem) { throw AssertionError(\"Item is not an instance of IconItem\") } view.showIcon(item.icon) view.reset() } } 上述代码有很多冗余的地方，其实很明显你就能看出MediaItemRenderer和IconItemRenderer在render()函数中存在着相同的逻辑，现在，我们用inline reified来改造它，首先将render函数中的逻辑提取出来： fun&lt;T> withCorrectType(toBeChecked: Item, block: (T) -> Unit) { if(toBeChecked !is T) { throw IllegalArgumentException(\"invalid Type\") } block.invoke(toBeChecked) } 然而，这样做并不能通过编译，会报错 Cannot check for instance of erased type: T 产生这种错误是因为泛型机制。 During the type erasure process, the Java compiler erases all type parameters and replaces each with its first bound if the type parameter is bounded,or Object if the type parameter is unbounded.-docs.oracle.com so, 可以防止防止泛型T被清除吗？在Kotlin中一切都有可能，使用inline reified，就能修复这个问题。 class MediaItemRenderer: Renderer { override fun render(view: View, item: Item) = with(view) { withCorrectType&lt;MediaItem>(item) { show {it.media()} reset() } } } class IconItemRenderer: Renderer { override fun render(view: View, item: Item) = with(view) { withCorrectType&lt;IconItem>(item) { clear() show {it.icon()} } } } inline fun&lt;reified T> withCorrectType(toBeChecked: Item, block: (T) -> Unit) { if(toBeChecked !is T) { throw ... } block.invoke(toBeChecked) } 使用reified修饰符Kotlin compiler保留了你的类型，当然这是必须在使用inline的前提下。 以上就是第二章的全部了，在第三章中我们将展示更多的Kotlin小技巧。 参考6 magic sugars that can make your Kotlin codebase happier — Part 2","link":"/2019/03/30/kotlin%E8%AF%AD%E6%B3%95%E7%B3%96Part2/"},{"title":"Kotlin Lambda and Extension","text":"Extension Function(扩展函数) Extension Function 能在已经存在的类中添加新的方法或者属性，即使这些类来自库或者SDK中。在函数内部，我们可以访问类的公共函数和属性而不需要任何限定符，就好像这个函数就在这个类的内部一样。（注意：从技术上将，它并没有修改现有类，只是在声明的类中创建了static public final函数） 举个栗子 object KotMain { @JvmStatic fun main(args: Array&lt;String>) { val person = \"snoopy\" person.say(\"hello\") } fun String.say(sth: String) { println(\"$this say $sth\") } } 反编译后我们可以看到生成的java代码 public final class KotMain { public static final KotMain INSTANCE; public static final void main(@NotNull String[] args) { Instrinsics.checkParameterIsNotNull(args, \"args\"); String person = \"snoopy\"; INSTANCE.say(person, \"hello\"); } public final void say(@NotNull String $this$say, @NotNull String sth) { Instrinsics.checkParameterIsNotNull($this$say, \"$this$say\"); Instrinsics.checkParameterIsNotNull(sth, \"sth\"); String var3 = $this$say + ' ' + sth; System.out.println(var3); } } 可以看到只是增加了一个final方法。 接下来看看如何在Android项目中运用它 可以生成任何Android View实例的函数 inline fun&lt;reified V: View> v(context: Context, init: V.() -> Unit): V{ val instance = V::class.java.getConstructor(context::class.java) val view = instace.newInstance(context) view.init() return view } dp-px拓展 fun View.dp2px(dp: Float) { return TypedValue.applyDimension(TypedValue.COMPLEX_UNIT_DIP, dp, context.resource.displayMetrics) } 添加fragment inline fun FragmentManager.inTransaction(func: FragmentTransaction.() -> Unit) { val fragmentTransaction = begainTransaction() fragmentTransaction.func() fragmentTransaction.commit() } //使用 supportFragmentManager.inTransaction { add(R.id.container, fragment) //other operation } High Order FunctionHigh Order Function 在 kotlin 的官网中有很明确的解释: Higher-Order FunctionsA higher-order function is a function that takes functions as parameters, or returns a function.高阶函数是将函数作为参数或返回函数的函数。 High Order Function 中函数作为参数的情况 inline fun test1(func:Int.() -> Unit) { func(1) } inline fun Int.test2(func:Int.() -> Unit) { func() } public final void test1(int $this$test1, Function1 call) { call.invoke($this$test) } public final void test2(Function1 call) { call.invoke(1) } Lambda with Receiver什么是Lambda with Receiver? Extension Function + Lambda = Lambda with Receiver，它允许你在没有任何限定符的情况下调用lambda中对象的方法。 inline function在kotlin中，函数是一等公民，所以我们可以传递函数或者像其它普通类型一样返回它们。然而，这些函数在运行时可能会产生一些性能上的问题，它们作为对象存储造成了额外的内存开销，这时候就轮到inline登场了，在一些使用High Order Function的场景中，我们一般用inline（内联）去修饰它，这样可以减少调用开销。我们依然从源码出发，通过反编译，看看使用High Order Function编译成Java是什么样子的。 object KotMain { @JvmStatic fun main(args: Array&lt;String>) { noInline { println(\"调用中\") } inlineFunc { println(\"调用中\") } } fun noInline(call: ()->Unit) { println(\"调用前\") call() println(\"调用后\") } inline fun inlineFunc(call: ()->Unit) { println(\"调用前\") call() println(\"调用后\") } } 再来看看java代码 public final class KotMain { public static final KotlinMain INSTANCE; public static final void main(String[] args) { //no inline INSTANCE.noInline(new Function() { @Override public void invoke() { System.out.println(\"调用中\"); } }) //inline System.out.println(\"调用前\"); System.out.println(\"调用中\"); System.out.println(\"调用后\"); } public final void noInline(Function func) { println(\"调用前\"); func.invoke() println(\"调用后\"); } } 大家可以非常直观的看到结论，不使用内联修饰符，每次调用这个函数都会初始化一个Function实例，显然会造成内存开销，而使用内联修饰符，不会创建Function实例，而会将回调函数内部的代码复制到call site中。 参考 kotlin-extension functionKotlin里的Extension Functions实现原理分析How to Add a Fragment the Kotlin way","link":"/2019/03/22/kotlin%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95/"},{"title":"高效的Okio","text":"Okio is a library that complements java.io and java.nio to make it much easier to access, store, and process your data. 正如Okio官网所说，它整合了java io 和nio让它们的更容易使用。此篇深入分析一下Okio高效的原因。 implementation \"com.squareup.okio:okio:2.7.0\" 目录 目录 Okio UML 基本用法 Buffer的角色 Segment结构与SegmentPool Okio超时机制 结束语 Okio UML sink负责写入，source负责读取 基本用法// 读取文件 val readFile = File(\"read\") val buffer = readFile.source().buffer() buffer.readString(Charset.forName(\"utf-8\")) // 写入文件 val writableFile = File(\"writable\") if (!writableFile.exists()) { writableFile.createNewFile() } val sink = writableFile.sink().buffer() sink.writeString(\"sink write in\", Charset.defaultCharset()) sink.flush() sink.close() 无论是读取还是写入，都是对java字节流做了一层包装，对于InputStream包装成了InputStreamSource，对于OutputStream包装成了OutputStreamSink。（对于output/input对于内存而言，output从内存写出，input从外部写入内存）对于Reader和Writer，没有做相关的扩展方法，可能是字符流已经使用了缓冲区吧。然后Source和Sink又被包装RealBufferedSource和RealBufferedSink，这些类的主要函数都以扩展函数的形式放在internal\\RealBufferedSource.kt和internal\\RealBufferedSink.kt文件中，为啥不放在对应的类中呢？个人觉得可能这些逻辑主要是跟Okio的Buffer相关，抽出来放在一起看起来更直观一些。 Buffer的角色字节流的读/写都会申请一遍内存空间用于存放读/写的数据，读写完之后再被回收，这样反复的申请内存显然是对系统性能有影响的。Buffer在Okio中起着重要的角色，它定义了一些读写的方法，并对申请的内存做了复用，节约了IO字节流反复申请内存的开销。使用Buffer之后，java字节流的读写逻辑变为先将数据放在可被回收复用的Segment中，然后等待后续处理。 Segment结构与SegmentPoolBuffer内部使用Segment保存数据，Segment用于存储读/写的字节码， internal class Segment { // 用于存储读/写数据 长度8192 @JvmField val data: ByteArray /** The next byte of application data byte to read in this segment. */ // 当前byteArray的读取位置 @JvmField var pos: Int = 0 /** The first byte of available data ready to be written to. */ // 可以理解为data当前的容量 @JvmField var limit: Int = 0 /** True if other segments or byte strings use the same byte array. */ // 与下面的owner互斥表示这个segment是共享的还是独占的 // 可能会影响到我们写入数据时是否需要创建新的segment @JvmField var shared: Boolean = false /** True if this segment owns the byte array and can append to it, extending `limit`. */ @JvmField var owner: Boolean = false /** Next segment in a linked or circularly-linked list. */ @JvmField var next: Segment? = null /** Previous segment in a circularly-linked list. */ @JvmField var prev: Segment? = null // 省略... } Segment是环状链表结构的节点。Buffer类中定义了许多读写相关的方法，简单的看下其中commonReadInt和commonWriteInt，看看有什么共通性。 internal inline fun Buffer.commonReadInt(): Int { if (size &lt; 4L) throw EOFException() // 从Buffer中获取head val segment = head!! // pos 读取的起始位置 var pos = segment.pos // segment中字节码的长度 val limit = segment.limit // If the int is split across multiple segments, delegate to readByte(). // 发现剩余的字节码的长度小于4，等于说剩余的长度不足一个int的长度啦，就直接去读byte吧 if (limit - pos &lt; 4L) { // shl 运算优先级要大于and return (readByte() and 0xff shl 24 or (readByte() and 0xff shl 16) or (readByte() and 0xff shl 8) // ktlint-disable no-multi-spaces or (readByte() and 0xff)) } val data = segment.data // 这里呢，在字节码数组中读取4位表示一个Int，第一个字节表示高8位，最后一个字节低8位，将这32位bit求和就得到读取的int值啦 val i = (data[pos++] and 0xff shl 24 or (data[pos++] and 0xff shl 16) or (data[pos++] and 0xff shl 8) or (data[pos++] and 0xff)) // 读取了4个字节，长度减4咯 size -= 4L // 当当前读取的位置与存储的上限位置相等表示读完啦 if (pos == limit) { // 改变头部的指向 head = segment.pop() // 将读取完的segment回收 SegmentPool.recycle(segment) } else { // 改变当前读取到的位置 segment.pos = pos } // 返回读取的int值 return i } internal inline fun Buffer.commonWriteInt(i: Int): Buffer { // 拿到一个可写入的segment，4表示int的长度，影响后面是否要创建新的segment val tail = writableSegment(4) val data = tail.data // 下面就是常规操作啦，写入一个int值并更新字节数组的长度和size的大小 var limit = tail.limit data[limit++] = (i ushr 24 and 0xff).toByte() data[limit++] = (i ushr 16 and 0xff).toByte() data[limit++] = (i ushr 8 and 0xff).toByte() // ktlint-disable no-multi-spaces data[limit++] = (i and 0xff).toByte() // ktlint-disable no-multi-spaces tail.limit = limit size += 4L return this } 从上面两个简单函数的实现上，我们可以看出，无论是读还是写，似乎都离不开segment这个结构体，并且Okio还贴心的创建了一个SegmentPool用于回收复用Segment。来看看SegmentPool的结构。 internal actual object SegmentPool { actual val MAX_SIZE = 64 * 1024 private val LOCK = Segment(ByteArray(0), pos = 0, limit = 0, shared = false, owner = false) // hash_bucket_count与处理器ALU个数有关，4舍5入保证是2的指数。这样能保证线程之间抢占cpu的可能性更低，我们创建线程池是不是也可以这么设计呢? private val HASH_BUCKET_COUNT = Integer.highestOneBit(Runtime.getRuntime().availableProcessors() * 2 - 1) /** * Hash buckets each containing a singly-linked list of segments. We use multiple hash buckets so * different threads don't race each other. We use thread IDs as hash keys because they're handy, * and because it may increase locality. * * We don't use [ThreadLocal] because we don't know how many threads the host process has and we * don't want to leak memory for the duration of a thread's life. */ // 对于io密集型场景，线程数 = cpu核心数 / (1 - 阻塞系数) （阻塞系数为该任务阻塞时间与（阻塞时间+计算时间）的比值）。可以简单设置为2倍cpu核心数 // 对于计算密集型场景，线程数 = cpu核心数 // hashBuckets的长度>=可用处理器长度，一般情况是一个线程对应一个Segment，但是也可能存在多个线程对应一个Segment的情况。 private val hashBuckets: Array&lt;AtomicReference&lt;Segment?>> = Array(HASH_BUCKET_COUNT) { AtomicReference&lt;Segment?>() } @JvmStatic actual fun take(): Segment { val firstRef = firstRef() // firstRef获取值并设置LOCK返回原值 val first = firstRef.getAndSet(LOCK) when { // 如果first为LOCK，没有占有锁，不会从池中拿segment first === LOCK -> { // We didn't acquire the lock. Don't take a pooled segment. return Segment() } // first == null当前占有锁但是segment池是空的。释放锁返回一个segment first == null -> { // We acquired the lock but the pool was empty. Unlock and return a new segment. firstRef.set(null) return Segment() } // 其它情况，获取到了锁并且segment pool不是空的。复用当前的Segment。 else -> { // We acquired the lock and the pool was not empty. Pop the first element and return it. firstRef.set(first.next) first.next = null first.limit = 0 return first } } } @JvmStatic actual fun recycle(segment: Segment) { require(segment.next == null &amp;&amp; segment.prev == null) // 如果Segment是共享的不能被回收 if (segment.shared) return // This segment cannot be recycled. val firstRef = firstRef() val first = firstRef.get() // 若当前锁被占用，不能被回收 if (first === LOCK) return // A take() is currently in progress. val firstLimit = first?.limit ?: 0 if (firstLimit >= MAX_SIZE) return // Pool is full. segment.next = first segment.pos = 0 // 更新缓存池的容量(头插法) segment.limit = firstLimit + Segment.SIZE // 如果当前值 == 预期值，则以原子方式将该值设置为给定的更新值。 // 如果成功，则返回 true。返回 false 指示实际值与预期值不相等。 if (!firstRef.compareAndSet(first, segment)) segment.next = null // If we raced another operation: Don't recycle this segment. } private fun firstRef(): AtomicReference&lt;Segment?> { // Get a value in [0..HASH_BUCKET_COUNT). val hashBucket = (Thread.currentThread().id and (HASH_BUCKET_COUNT - 1L)).toInt() return hashBuckets[hashBucket] } } 去掉些注释，代码量不过百来行，但确是整个框架的核心所在。早期版本的SegmentPool简单粗暴的使用synchronized将整个SegmentPool加了锁，访问效率比较低。改良后的SegmentPool是一个无锁的单链表结构，采用哨兵LOCK和CAS机制保证线程的安全性，内部的hashBuckets能保证对于每个线程都有一个独占的Segment单链表，不同的线程之间不会产生竞争。 Okio超时机制Okio种Timeout负责管理timeout和deadline，两者的使用场景略有不同，timeout主要用于socket通信超时，deadline用于读写操作是否在规定的期限内执行。接下来看看实际中是如何使用它们的。 fun main() { // 初始化一个文件输出流 val ops = FileOutputStream(\"writable\") val sink = ops.sink() val timeout = sink.timeout() // 设置deadline为5秒 timeout.deadline(5, TimeUnit.SECONDS) // 当前线程睡眠6s Thread.sleep(6_000) val buffer = sink.buffer() // 执行写入操作 buffer.writeString(\"after 10 second\", Charset.defaultCharset()) buffer.close() } 执行上述代码后，发现抛出一下异常 Exception in thread \"main\" java.io.InterruptedIOException: deadline reached at okio.Timeout.throwIfReached(Timeout.kt:102) at okio.OutputStreamSink.write(JvmOkio.kt:50) at okio.RealBufferedSink.close(RealBufferedSink.kt:260) at MainKt.main(Main.kt:21) at MainKt.main(Main.kt) 在设置timeout.deadline，会设置timeout中deadlineNanoTime，为当前系统时间加上deadline，调用buffer.close最终会调用到OutputStreamSink的write函数，其中的timeout.throwIfReached()判断是否到达deadline的时间点。 open fun throwIfReached() { if (Thread.interrupted()) { Thread.currentThread().interrupt() // Retain interrupted status. throw InterruptedIOException(\"interrupted\") } // deadline time 与当前系统时间的差值小于0，抛出异常 if (hasDeadline &amp;&amp; deadlineNanoTime - System.nanoTime() &lt;= 0) { throw InterruptedIOException(\"deadline reached\") } } 再看看Socket.sink() // SocketAsyncTimeout是AsyncTimeout子类，实际上是用它控制timeout的 @Throws(IOException::class) fun Socket.sink(): Sink { val timeout = SocketAsyncTimeout(this) val sink = OutputStreamSink(getOutputStream(), timeout) return timeout.sink(sink) } fun AsyncTimeout.source(source: Source): Source { return object : Source { override fun read(sink: Buffer, byteCount: Long): Long { // source.read被withTimeout包装了一层 return withTimeout { source.read(sink, byteCount) } } override fun close() { withTimeout { source.close() } } override fun timeout() = this@AsyncTimeout override fun toString() = \"AsyncTimeout.source($source)\" } } inline fun &lt;T> withTimeout(block: () -> T): T { var throwOnTimeout = false // 超时逻辑所在 enter() // 省略。。。 } fun enter() { check(!inQueue) { \"Unbalanced enter/exit\" } val timeoutNanos = timeoutNanos() val hasDeadline = hasDeadline() if (timeoutNanos == 0L &amp;&amp; !hasDeadline) { return // No timeout and no deadline? Don't bother with the queue. } inQueue = true // 调度timeout，开启watchdog线程，watchdog会计算当前timeout节点是否超时若达到了超时时间将timeout从当前链表中移除并返回执行timeout.timeout()，当没有节点时watchdog自动挂起1分钟。 scheduleTimeout(this, timeoutNanos, hasDeadline) } scheduleTimeout处理AysncTimeout单链表，并会通过timeout时间与deadline时间对节点排序，scheduleTimeout启动了Watchdog线程，比对头部节点超时时间与当前系统时间，若发现超时从链表中移除当前节点执行timeout.timeout()关闭socket。 结束语Okio核心思想在于Segment与SegmentPool，相比用传统方法使用io流，减少反复申请内存对系统性能的开销。SegmentPool中对多线程编程的情况做了优化，减少了线程之间的竞争。通读一遍下来，你会发现Okio结构清晰，运用了大量的设计思想，在日常的开发过程中，如果可以合理地学习利用，相信我们也能开发出高性能的应用。","link":"/2020/07/09/%E9%AB%98%E6%95%88%E7%9A%84Okio/"}],"tags":[{"name":"framework","slug":"framework","link":"/tags/framework/"},{"name":"jetpack","slug":"jetpack","link":"/tags/jetpack/"},{"name":"library","slug":"library","link":"/tags/library/"},{"name":"基础","slug":"基础","link":"/tags/%E5%9F%BA%E7%A1%80/"},{"name":"android","slug":"android","link":"/tags/android/"},{"name":"tools","slug":"tools","link":"/tags/tools/"},{"name":"其他","slug":"其他","link":"/tags/%E5%85%B6%E4%BB%96/"}],"categories":[{"name":"Android","slug":"Android","link":"/categories/Android/"},{"name":"Kotlin","slug":"Kotlin","link":"/categories/Kotlin/"},{"name":"tools","slug":"tools","link":"/categories/tools/"},{"name":"Jenkins","slug":"Jenkins","link":"/categories/Jenkins/"},{"name":"ssr","slug":"ssr","link":"/categories/ssr/"}]}